{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAsmjf9GjBgS",
        "outputId": "68d417a1-185e-4999-a760-f55b994725b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tabula-py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8upLeH1eChMQ",
        "outputId": "7e590564-9185-4b48-8a3f-f0aa450335c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tabula-py in /usr/local/lib/python3.10/dist-packages (2.10.0)\n",
            "Requirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.10/dist-packages (from tabula-py) (2.2.2)\n",
            "Requirement already satisfied: numpy>1.24.4 in /usr/local/lib/python3.10/dist-packages (from tabula-py) (1.26.4)\n",
            "Requirement already satisfied: distro in /usr/local/lib/python3.10/dist-packages (from tabula-py) (1.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.3->tabula-py) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.3->tabula-py) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.3->tabula-py) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.25.3->tabula-py) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "45KHc9xhjEOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "excel_folder_path = '/content/drive/My Drive/Patient data individual/2024-Data/SCH_asthma_114'  # Replace 'your_folder_name' with your actual folder name\n",
        "\n",
        "# Define output folder for CSVs\n",
        "csv_output_folder = '/content/drive/My Drive/Patient data individual/2024-Data/csv files'  # Replace 'your_output_folder_name' with the desired output folder name\n",
        "os.makedirs(csv_output_folder, exist_ok=True)\n",
        "\n",
        "# Step 2: Loop through each Excel file and convert to CSV\n",
        "for file_name in os.listdir(excel_folder_path):\n",
        "    if file_name.endswith('.xlsx') or file_name.endswith('.xls'):\n",
        "        # Construct full file path\n",
        "        file_path = os.path.join(excel_folder_path, file_name)\n",
        "\n",
        "        # Read Excel file into a DataFrame\n",
        "        df = pd.read_excel(file_path)\n",
        "\n",
        "        # Construct the CSV file path\n",
        "        csv_file_path = os.path.join(csv_output_folder, f\"{os.path.splitext(file_name)[0]}.csv\")\n",
        "\n",
        "        # Save DataFrame as CSV\n",
        "        df.to_csv(csv_file_path, index=False)\n",
        "        print(f\"Converted {file_name} to CSV at {csv_file_path}\")\n",
        "\n",
        "print(\"All Excel files have been converted to CSV.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vw4lYeywjRa9",
        "outputId": "f5a8c596-d38e-4677-e924-8dacb4826a39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted SB-059 (2021-10-06).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-059 (2021-10-06).csv\n",
            "Converted SB-119 (2018-12-17).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-119 (2018-12-17).csv\n",
            "Converted SB-026 (2018-02-26).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-026 (2018-02-26).csv\n",
            "Converted SB-046 (2017-10-11).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-046 (2017-10-11).csv\n",
            "Converted SB-035 (2017-09-11).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-035 (2017-09-11).csv\n",
            "Converted SB-003 (2020-03-29).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-003 (2020-03-29).csv\n",
            "Converted SB-007 (2017-05-15).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-007 (2017-05-15).csv\n",
            "Converted SB-018 (2017-09-13).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-018 (2017-09-13).csv\n",
            "Converted SB-072 (2021-10-18).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-072 (2021-10-18).csv\n",
            "Converted SB-015 (2018-05-20).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-015 (2018-05-20).csv\n",
            "Converted SB-081 (2021-04-05).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-081 (2021-04-05).csv\n",
            "Converted SB-052 (2017-03-08).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-052 (2017-03-08).csv\n",
            "Converted SB-122 (2022-01-19).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-122 (2022-01-19).csv\n",
            "Converted SB-049 (2019-09-23).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-049 (2019-09-23).csv\n",
            "Converted SB-023 (2020-04-06).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-023 (2020-04-06).csv\n",
            "Converted SB-043 (2020-04-01).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-043 (2020-04-01).csv\n",
            "Converted SB-009 (2019-04-09).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-009 (2019-04-09).csv\n",
            "Converted SB-091 (2018-07-31).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-091 (2018-07-31).csv\n",
            "Converted SB-047 (2020-06-08).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-047 (2020-06-08).csv\n",
            "Converted SB-057 (2017-07-20).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-057 (2017-07-20).csv\n",
            "Converted SB-063 (2019-04-21).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-063 (2019-04-21).csv\n",
            "Converted SB-022 (2021-04-30).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-022 (2021-04-30).csv\n",
            "Converted SB-101 (2018-05-28).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-101 (2018-05-28).csv\n",
            "Converted SB-016 (2018-01-31).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-016 (2018-01-31).csv\n",
            "Converted SB-028 (2018-08-08).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-028 (2018-08-08).csv\n",
            "Converted SB-031 (2018-05-15).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-031 (2018-05-15).csv\n",
            "Converted SB-066 (2017-08-14).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-066 (2017-08-14).csv\n",
            "Converted SB-080 (2019-04-27).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-080 (2019-04-27).csv\n",
            "Converted SB-053 (2018-11-06).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-053 (2018-11-06).csv\n",
            "Converted SB-067 (2018-12-17).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-067 (2018-12-17).csv\n",
            "Converted SB-116 (2018-04-02).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-116 (2018-04-02).csv\n",
            "Converted SB-011 (2022-01-19).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-011 (2022-01-19).csv\n",
            "Converted SB-092 (2020-06-30).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-092 (2020-06-30).csv\n",
            "Converted SB-036 (2019-10-13).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-036 (2019-10-13).csv\n",
            "Converted SB-020 (2017-10-12).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-020 (2017-10-12).csv\n",
            "Converted SB-005 (2017-03-11).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-005 (2017-03-11).csv\n",
            "Converted SB-096 (2020-05-04).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-096 (2020-05-04).csv\n",
            "Converted SB-064 (2020-05-10).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-064 (2020-05-10).csv\n",
            "Converted SB-013 (2017-03-18).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-013 (2017-03-18).csv\n",
            "Converted SB-017 (2021-11-30).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-017 (2021-11-30).csv\n",
            "Converted SB-048 (2021-04-19).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-048 (2021-04-19).csv\n",
            "Converted SB-040 (2021-09-30).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-040 (2021-09-30).csv\n",
            "Converted SB-083 (2018-06-04).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-083 (2018-06-04).csv\n",
            "Converted SB-033 (2020-03-28).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-033 (2020-03-28).csv\n",
            "Converted SB-062 (2017-10-16).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-062 (2017-10-16).csv\n",
            "Converted SB-004 (2021-09-04).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-004 (2021-09-04).csv\n",
            "Converted SB-065 (2017-02-28).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-065 (2017-02-28).csv\n",
            "Converted SB-051 (2017-01-29).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-051 (2017-01-29).csv\n",
            "Converted SB-050 (2018-03-09).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-050 (2018-03-09).csv\n",
            "Converted SB-088 (2021-05-31).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-088 (2021-05-31).csv\n",
            "Converted SB-021 (2017-09-12).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-021 (2017-09-12).csv\n",
            "Converted SB-012 (2018-05-15).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-012 (2018-05-15).csv\n",
            "Converted SB-110 (2019-02-23).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-110 (2019-02-23).csv\n",
            "Converted SB-068 (2021-01-31).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-068 (2021-01-31).csv\n",
            "Converted SB-117 (2019-02-13).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-117 (2019-02-13).csv\n",
            "Converted SB-037 (2018-07-23).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-037 (2018-07-23).csv\n",
            "Converted SB-084 (2021-02-23).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-084 (2021-02-23).csv\n",
            "Converted SB-029 (2020-04-19).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-029 (2020-04-19).csv\n",
            "Converted SB-095 (2021-06-30).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-095 (2021-06-30).csv\n",
            "Converted SB-102 (2016-06-05).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-102 (2016-06-05).csv\n",
            "Converted SB-074 (2017-03-13).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-074 (2017-03-13).csv\n",
            "Converted SB-001 (2020-02-05).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-001 (2020-02-05).csv\n",
            "Converted SB-086 (2017-10-10).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-086 (2017-10-10).csv\n",
            "Converted SB-058 (2021-11-29).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-058 (2021-11-29).csv\n",
            "Converted SB-089 (2021-05-02).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-089 (2021-05-02).csv\n",
            "Converted SB-077 (2018-05-14).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-077 (2018-05-14).csv\n",
            "Converted SB-044 (2019-04-03).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-044 (2019-04-03).csv\n",
            "Converted SB-099 (2018-01-31).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-099 (2018-01-31).csv\n",
            "Converted SB-073 (2021-04-03).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-073 (2021-04-03).csv\n",
            "Converted SB-024 (2017-08-30).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-024 (2017-08-30).csv\n",
            "Converted SB-054 (2017-04-27).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-054 (2017-04-27).csv\n",
            "Converted SB-085 (2020-07-31).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-085 (2020-07-31).csv\n",
            "Converted SB-042 (2019-05-20).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-042 (2019-05-20).csv\n",
            "Converted SB-025 (2019-10-14).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-025 (2019-10-14).csv\n",
            "Converted SB-060 (2018-02-25).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-060 (2018-02-25).csv\n",
            "Converted SB-082 (2019-03-11).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-082 (2019-03-11).csv\n",
            "Converted SB-121 (2019-07-15).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-121 (2019-07-15).csv\n",
            "Converted SB-115 (2020-04-29).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-115 (2020-04-29).csv\n",
            "Converted SB-118 (2018-07-12).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-118 (2018-07-12).csv\n",
            "Converted SB-006 (2020-01-08).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-006 (2020-01-08).csv\n",
            "Converted SB-019 (2018-05-26).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-019 (2018-05-26).csv\n",
            "Converted SB-075 (2019-03-18).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-075 (2019-03-18).csv\n",
            "Converted SB-061 (2017-05-24).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-061 (2017-05-24).csv\n",
            "Converted SB-055 (2017-04-24).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-055 (2017-04-24).csv\n",
            "Converted SB-078 (2019-04-17).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-078 (2019-04-17).csv\n",
            "Converted SB-093 (2019-03-19).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-093 (2019-03-19).csv\n",
            "Converted SB-039 (2017-05-31).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-039 (2017-05-31).csv\n",
            "Converted SB-010 (2017-07-24).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-010 (2017-07-24).csv\n",
            "Converted SB-111 (2017-08-28).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-111 (2017-08-28).csv\n",
            "Converted SB-008 (2021-06-30).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-008 (2021-06-30).csv\n",
            "Converted SB-002 (2017-01-29).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-002 (2017-01-29).csv\n",
            "Converted SB-108 (2019-01-16).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-108 (2019-01-16).csv\n",
            "Converted SB-070 (2019-10-16).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-070 (2019-10-16).csv\n",
            "Converted SB-112 (2021-10-29.xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-112 (2021-10-29.csv\n",
            "Converted SB-056 (2020-10-28).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-056 (2020-10-28).csv\n",
            "Converted SB-071 (2018-08-31).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-071 (2018-08-31).csv\n",
            "Converted SB-032 (2017-10-10).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-032 (2017-10-10).csv\n",
            "Converted SB-079 (2021-12-30).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-079 (2021-12-30).csv\n",
            "Converted SB-014 (2022-01-10).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-014 (2022-01-10).csv\n",
            "Converted SB-120 (2018-07-18).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-120 (2018-07-18).csv\n",
            "All Excel files have been converted to CSV.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the folder where your CSV files are located\n",
        "csv_folder_path = '/content/drive/My Drive/Patient data individual/2024-Data/csv files'\n",
        "\n",
        "# Columns to drop based on the names you provided\n",
        "columns_to_drop = [\n",
        "    'B. Monthly record', 'Unnamed: 3', 'Unnamed: 4',\n",
        "    'Unnamed: 5', 'Unnamed: 8', 'D. PEFR w SmartOne', 'Unnamed: 10'\n",
        "]\n",
        "\n",
        "# Loop through each CSV file, drop the specified columns, and load them into a list of DataFrames\n",
        "processed_dfs = []\n",
        "for file_name in os.listdir(csv_folder_path):\n",
        "    if file_name.endswith('.csv'):\n",
        "        file_path = os.path.join(csv_folder_path, file_name)\n",
        "\n",
        "        # Read the CSV file\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        # Drop the specified columns if they exist in the DataFrame\n",
        "        df = df.drop(columns=[col for col in columns_to_drop if col in df.columns], errors='ignore')\n",
        "\n",
        "        # Append the processed DataFrame to the list\n",
        "        processed_dfs.append(df)\n",
        "        print(f\"Processed {file_name}\")\n",
        "\n",
        "# Combine all processed DataFrames into a single DataFrame if needed\n",
        "combined_df = pd.concat(processed_dfs, ignore_index=True)\n",
        "\n",
        "# Display or save the combined DataFrame\n",
        "print(combined_df.head())\n",
        "# To save the combined DataFrame as a new CSV\n",
        "combined_df.to_csv('/content/drive/My Drive/Patient data individual/2024-Data/processed_csv_files', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFEYp-OCuWG3",
        "outputId": "803ead97-ccf1-4708-f7ed-b0179b1aea83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed SB-059 (2021-10-06).csv\n",
            "Processed SB-119 (2018-12-17).csv\n",
            "Processed SB-026 (2018-02-26).csv\n",
            "Processed SB-046 (2017-10-11).csv\n",
            "Processed SB-035 (2017-09-11).csv\n",
            "Processed SB-003 (2020-03-29).csv\n",
            "Processed SB-007 (2017-05-15).csv\n",
            "Processed SB-018 (2017-09-13).csv\n",
            "Processed SB-072 (2021-10-18).csv\n",
            "Processed SB-015 (2018-05-20).csv\n",
            "Processed SB-081 (2021-04-05).csv\n",
            "Processed SB-052 (2017-03-08).csv\n",
            "Processed SB-122 (2022-01-19).csv\n",
            "Processed SB-049 (2019-09-23).csv\n",
            "Processed SB-023 (2020-04-06).csv\n",
            "Processed SB-043 (2020-04-01).csv\n",
            "Processed SB-009 (2019-04-09).csv\n",
            "Processed SB-091 (2018-07-31).csv\n",
            "Processed SB-047 (2020-06-08).csv\n",
            "Processed SB-057 (2017-07-20).csv\n",
            "Processed SB-063 (2019-04-21).csv\n",
            "Processed SB-022 (2021-04-30).csv\n",
            "Processed SB-101 (2018-05-28).csv\n",
            "Processed SB-016 (2018-01-31).csv\n",
            "Processed SB-028 (2018-08-08).csv\n",
            "Processed SB-031 (2018-05-15).csv\n",
            "Processed SB-066 (2017-08-14).csv\n",
            "Processed SB-080 (2019-04-27).csv\n",
            "Processed SB-053 (2018-11-06).csv\n",
            "Processed SB-067 (2018-12-17).csv\n",
            "Processed SB-116 (2018-04-02).csv\n",
            "Processed SB-011 (2022-01-19).csv\n",
            "Processed SB-092 (2020-06-30).csv\n",
            "Processed SB-036 (2019-10-13).csv\n",
            "Processed SB-020 (2017-10-12).csv\n",
            "Processed SB-005 (2017-03-11).csv\n",
            "Processed SB-096 (2020-05-04).csv\n",
            "Processed SB-064 (2020-05-10).csv\n",
            "Processed SB-013 (2017-03-18).csv\n",
            "Processed SB-017 (2021-11-30).csv\n",
            "Processed SB-048 (2021-04-19).csv\n",
            "Processed SB-040 (2021-09-30).csv\n",
            "Processed SB-083 (2018-06-04).csv\n",
            "Processed SB-033 (2020-03-28).csv\n",
            "Processed SB-062 (2017-10-16).csv\n",
            "Processed SB-004 (2021-09-04).csv\n",
            "Processed SB-065 (2017-02-28).csv\n",
            "Processed SB-051 (2017-01-29).csv\n",
            "Processed SB-050 (2018-03-09).csv\n",
            "Processed SB-088 (2021-05-31).csv\n",
            "Processed SB-021 (2017-09-12).csv\n",
            "Processed SB-012 (2018-05-15).csv\n",
            "Processed SB-110 (2019-02-23).csv\n",
            "Processed SB-068 (2021-01-31).csv\n",
            "Processed SB-117 (2019-02-13).csv\n",
            "Processed SB-037 (2018-07-23).csv\n",
            "Processed SB-084 (2021-02-23).csv\n",
            "Processed SB-029 (2020-04-19).csv\n",
            "Processed SB-095 (2021-06-30).csv\n",
            "Processed SB-102 (2016-06-05).csv\n",
            "Processed SB-074 (2017-03-13).csv\n",
            "Processed SB-001 (2020-02-05).csv\n",
            "Processed SB-086 (2017-10-10).csv\n",
            "Processed SB-058 (2021-11-29).csv\n",
            "Processed SB-089 (2021-05-02).csv\n",
            "Processed SB-077 (2018-05-14).csv\n",
            "Processed SB-044 (2019-04-03).csv\n",
            "Processed SB-099 (2018-01-31).csv\n",
            "Processed SB-073 (2021-04-03).csv\n",
            "Processed SB-024 (2017-08-30).csv\n",
            "Processed SB-054 (2017-04-27).csv\n",
            "Processed SB-085 (2020-07-31).csv\n",
            "Processed SB-042 (2019-05-20).csv\n",
            "Processed SB-025 (2019-10-14).csv\n",
            "Processed SB-060 (2018-02-25).csv\n",
            "Processed SB-082 (2019-03-11).csv\n",
            "Processed SB-121 (2019-07-15).csv\n",
            "Processed SB-115 (2020-04-29).csv\n",
            "Processed SB-118 (2018-07-12).csv\n",
            "Processed SB-006 (2020-01-08).csv\n",
            "Processed SB-019 (2018-05-26).csv\n",
            "Processed SB-075 (2019-03-18).csv\n",
            "Processed SB-061 (2017-05-24).csv\n",
            "Processed SB-055 (2017-04-24).csv\n",
            "Processed SB-078 (2019-04-17).csv\n",
            "Processed SB-093 (2019-03-19).csv\n",
            "Processed SB-039 (2017-05-31).csv\n",
            "Processed SB-010 (2017-07-24).csv\n",
            "Processed SB-111 (2017-08-28).csv\n",
            "Processed SB-008 (2021-06-30).csv\n",
            "Processed SB-002 (2017-01-29).csv\n",
            "Processed SB-108 (2019-01-16).csv\n",
            "Processed SB-070 (2019-10-16).csv\n",
            "Processed SB-112 (2021-10-29.csv\n",
            "Processed SB-056 (2020-10-28).csv\n",
            "Processed SB-071 (2018-08-31).csv\n",
            "Processed SB-032 (2017-10-10).csv\n",
            "Processed SB-079 (2021-12-30).csv\n",
            "Processed SB-014 (2022-01-10).csv\n",
            "Processed SB-120 (2018-07-18).csv\n",
            "        Unnamed: 0           Unnamed: 1 Monthly record     PEFR  \\\n",
            "0               ID             Date(예시)         Normal  Morning   \n",
            "1           SB-059  2016-10-01 00:00:00            NaN      480   \n",
            "2              NaN  2016-10-02 00:00:00            NaN      470   \n",
            "3  2016/10~2017/09  2016-10-03 00:00:00            NaN      470   \n",
            "4  2017/09~2018/07  2016-10-04 00:00:00            NaN      NaN   \n",
            "\n",
            "           Unnamed: 7 PEFR w SmartOne Unnamed: 11 Medication Unnamed: 13  \\\n",
            "0  Afternoon (2-4 pm)         Morning  other time        흡입약         내복약   \n",
            "1                 450             NaN         NaN        NaN         NaN   \n",
            "2                 440             NaN         NaN        NaN         NaN   \n",
            "3                 NaN             NaN         NaN        NaN         NaN   \n",
            "4                 440             NaN         NaN        NaN         NaN   \n",
            "\n",
            "  C. PEFR E. Medication A. Patient Information  \n",
            "0     NaN           NaN                    NaN  \n",
            "1     NaN           NaN                    NaN  \n",
            "2     NaN           NaN                    NaN  \n",
            "3     NaN           NaN                    NaN  \n",
            "4     NaN           NaN                    NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define the folder where your Excel files are located\n",
        "input_folder_path = '/content/drive/My Drive/Patient data individual/2024-Data/SCH_asthma_114'  # Replace with your actual folder name\n",
        "\n",
        "# Define output folder for intermediate CSVs and final processed CSVs\n",
        "output_folder_path = '/content/drive/My Drive/Patient data individual/2024-Data/csv files'\n",
        "processed_csv_folder = '/content/drive/My Drive/Patient data individual/2024-Data/processed_csv'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "os.makedirs(processed_csv_folder, exist_ok=True)\n",
        "\n",
        "# Columns to drop based on the names you provided\n",
        "columns_to_drop = [\n",
        "    'B. Monthly record', 'Unnamed: 3', 'Unnamed: 4',\n",
        "    'Unnamed: 5', 'Unnamed: 8', 'D. PEFR w SmartOne', 'Unnamed: 10'\n",
        "]\n",
        "\n",
        "# Step 1: Convert each Excel file to CSV\n",
        "for file_name in os.listdir(input_folder_path):\n",
        "    if file_name.endswith('.xlsx') or file_name.endswith('.xls'):\n",
        "        # Construct full file path\n",
        "        file_path = os.path.join(input_folder_path, file_name)\n",
        "\n",
        "        # Read Excel file into a DataFrame\n",
        "        df = pd.read_excel(file_path)\n",
        "\n",
        "        # Construct the CSV file path for the intermediate CSV\n",
        "        csv_file_path = os.path.join(output_folder_path, f\"{os.path.splitext(file_name)[0]}.csv\")\n",
        "\n",
        "        # Save DataFrame as CSV\n",
        "        df.to_csv(csv_file_path, index=False)\n",
        "        print(f\"Converted {file_name} to CSV at {csv_file_path}\")\n",
        "\n",
        "# Step 2: Read each CSV file, drop specific columns, and find the longest consecutive sequence in 'Unnamed: 1'\n",
        "for file_name in os.listdir(output_folder_path):\n",
        "    if file_name.endswith('.csv'):\n",
        "        # Construct full file path for the intermediate CSV\n",
        "        csv_file_path = os.path.join(output_folder_path, file_name)\n",
        "\n",
        "        # Read the CSV file\n",
        "        df = pd.read_csv(csv_file_path)\n",
        "\n",
        "        # Drop the specified columns if they exist in the DataFrame\n",
        "        df = df.drop(columns=[col for col in columns_to_drop if col in df.columns], errors='ignore')\n",
        "\n",
        "        # Step 2.1: Find the longest consecutive sequence in 'Unnamed: 1'\n",
        "        if 'Unnamed: 1' in df.columns:\n",
        "            max_sequence = 0\n",
        "            current_sequence = 0\n",
        "\n",
        "            for i in range(1, len(df)):\n",
        "                if pd.notna(df['Unnamed: 1'].iloc[i]) and df['Unnamed: 1'].iloc[i] == df['Unnamed: 1'].iloc[i - 1]:\n",
        "                    current_sequence += 1\n",
        "                    max_sequence = max(max_sequence, current_sequence)\n",
        "                else:\n",
        "                    current_sequence = 1  # Reset sequence when the value changes\n",
        "\n",
        "            print(f\"Longest consecutive sequence in 'Unnamed: 1' for {file_name}: {max_sequence} rows\")\n",
        "\n",
        "        # Construct the file path for the processed CSV\n",
        "        processed_csv_file_path = os.path.join(processed_csv_folder, file_name)\n",
        "\n",
        "        # Save the processed DataFrame as a new CSV\n",
        "        df.to_csv(processed_csv_file_path, index=False)\n",
        "        print(f\"Processed {file_name} and saved without specified columns at {processed_csv_file_path}\")\n",
        "\n",
        "print(\"All Excel files have been converted and processed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XW3RpVCDxkzI",
        "outputId": "ec04129b-9649-4f82-84fd-aff88e304b98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted SB-059 (2021-10-06).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-059 (2021-10-06).csv\n",
            "Converted SB-119 (2018-12-17).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-119 (2018-12-17).csv\n",
            "Converted SB-026 (2018-02-26).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-026 (2018-02-26).csv\n",
            "Converted SB-046 (2017-10-11).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-046 (2017-10-11).csv\n",
            "Converted SB-035 (2017-09-11).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-035 (2017-09-11).csv\n",
            "Converted SB-003 (2020-03-29).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-003 (2020-03-29).csv\n",
            "Converted SB-007 (2017-05-15).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-007 (2017-05-15).csv\n",
            "Converted SB-018 (2017-09-13).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-018 (2017-09-13).csv\n",
            "Converted SB-072 (2021-10-18).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-072 (2021-10-18).csv\n",
            "Converted SB-015 (2018-05-20).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-015 (2018-05-20).csv\n",
            "Converted SB-081 (2021-04-05).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-081 (2021-04-05).csv\n",
            "Converted SB-052 (2017-03-08).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-052 (2017-03-08).csv\n",
            "Converted SB-122 (2022-01-19).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-122 (2022-01-19).csv\n",
            "Converted SB-049 (2019-09-23).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-049 (2019-09-23).csv\n",
            "Converted SB-023 (2020-04-06).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-023 (2020-04-06).csv\n",
            "Converted SB-043 (2020-04-01).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-043 (2020-04-01).csv\n",
            "Converted SB-009 (2019-04-09).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-009 (2019-04-09).csv\n",
            "Converted SB-091 (2018-07-31).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-091 (2018-07-31).csv\n",
            "Converted SB-047 (2020-06-08).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-047 (2020-06-08).csv\n",
            "Converted SB-057 (2017-07-20).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-057 (2017-07-20).csv\n",
            "Converted SB-063 (2019-04-21).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-063 (2019-04-21).csv\n",
            "Converted SB-022 (2021-04-30).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-022 (2021-04-30).csv\n",
            "Converted SB-101 (2018-05-28).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-101 (2018-05-28).csv\n",
            "Converted SB-016 (2018-01-31).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-016 (2018-01-31).csv\n",
            "Converted SB-028 (2018-08-08).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-028 (2018-08-08).csv\n",
            "Converted SB-031 (2018-05-15).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-031 (2018-05-15).csv\n",
            "Converted SB-066 (2017-08-14).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-066 (2017-08-14).csv\n",
            "Converted SB-080 (2019-04-27).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-080 (2019-04-27).csv\n",
            "Converted SB-053 (2018-11-06).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-053 (2018-11-06).csv\n",
            "Converted SB-067 (2018-12-17).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-067 (2018-12-17).csv\n",
            "Converted SB-116 (2018-04-02).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-116 (2018-04-02).csv\n",
            "Converted SB-011 (2022-01-19).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-011 (2022-01-19).csv\n",
            "Converted SB-092 (2020-06-30).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-092 (2020-06-30).csv\n",
            "Converted SB-036 (2019-10-13).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-036 (2019-10-13).csv\n",
            "Converted SB-020 (2017-10-12).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-020 (2017-10-12).csv\n",
            "Converted SB-005 (2017-03-11).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-005 (2017-03-11).csv\n",
            "Converted SB-096 (2020-05-04).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-096 (2020-05-04).csv\n",
            "Converted SB-064 (2020-05-10).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-064 (2020-05-10).csv\n",
            "Converted SB-013 (2017-03-18).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-013 (2017-03-18).csv\n",
            "Converted SB-017 (2021-11-30).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-017 (2021-11-30).csv\n",
            "Converted SB-048 (2021-04-19).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-048 (2021-04-19).csv\n",
            "Converted SB-040 (2021-09-30).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-040 (2021-09-30).csv\n",
            "Converted SB-083 (2018-06-04).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-083 (2018-06-04).csv\n",
            "Converted SB-033 (2020-03-28).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-033 (2020-03-28).csv\n",
            "Converted SB-062 (2017-10-16).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-062 (2017-10-16).csv\n",
            "Converted SB-004 (2021-09-04).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-004 (2021-09-04).csv\n",
            "Converted SB-065 (2017-02-28).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-065 (2017-02-28).csv\n",
            "Converted SB-051 (2017-01-29).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-051 (2017-01-29).csv\n",
            "Converted SB-050 (2018-03-09).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-050 (2018-03-09).csv\n",
            "Converted SB-088 (2021-05-31).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-088 (2021-05-31).csv\n",
            "Converted SB-021 (2017-09-12).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-021 (2017-09-12).csv\n",
            "Converted SB-012 (2018-05-15).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-012 (2018-05-15).csv\n",
            "Converted SB-110 (2019-02-23).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-110 (2019-02-23).csv\n",
            "Converted SB-068 (2021-01-31).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-068 (2021-01-31).csv\n",
            "Converted SB-117 (2019-02-13).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-117 (2019-02-13).csv\n",
            "Converted SB-037 (2018-07-23).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-037 (2018-07-23).csv\n",
            "Converted SB-084 (2021-02-23).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-084 (2021-02-23).csv\n",
            "Converted SB-029 (2020-04-19).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-029 (2020-04-19).csv\n",
            "Converted SB-095 (2021-06-30).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-095 (2021-06-30).csv\n",
            "Converted SB-102 (2016-06-05).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-102 (2016-06-05).csv\n",
            "Converted SB-074 (2017-03-13).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-074 (2017-03-13).csv\n",
            "Converted SB-001 (2020-02-05).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-001 (2020-02-05).csv\n",
            "Converted SB-086 (2017-10-10).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-086 (2017-10-10).csv\n",
            "Converted SB-058 (2021-11-29).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-058 (2021-11-29).csv\n",
            "Converted SB-089 (2021-05-02).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-089 (2021-05-02).csv\n",
            "Converted SB-077 (2018-05-14).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-077 (2018-05-14).csv\n",
            "Converted SB-044 (2019-04-03).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-044 (2019-04-03).csv\n",
            "Converted SB-099 (2018-01-31).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-099 (2018-01-31).csv\n",
            "Converted SB-073 (2021-04-03).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-073 (2021-04-03).csv\n",
            "Converted SB-024 (2017-08-30).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-024 (2017-08-30).csv\n",
            "Converted SB-054 (2017-04-27).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-054 (2017-04-27).csv\n",
            "Converted SB-085 (2020-07-31).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-085 (2020-07-31).csv\n",
            "Converted SB-042 (2019-05-20).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-042 (2019-05-20).csv\n",
            "Converted SB-025 (2019-10-14).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-025 (2019-10-14).csv\n",
            "Converted SB-060 (2018-02-25).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-060 (2018-02-25).csv\n",
            "Converted SB-082 (2019-03-11).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-082 (2019-03-11).csv\n",
            "Converted SB-121 (2019-07-15).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-121 (2019-07-15).csv\n",
            "Converted SB-115 (2020-04-29).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-115 (2020-04-29).csv\n",
            "Converted SB-118 (2018-07-12).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-118 (2018-07-12).csv\n",
            "Converted SB-006 (2020-01-08).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-006 (2020-01-08).csv\n",
            "Converted SB-019 (2018-05-26).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-019 (2018-05-26).csv\n",
            "Converted SB-075 (2019-03-18).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-075 (2019-03-18).csv\n",
            "Converted SB-061 (2017-05-24).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-061 (2017-05-24).csv\n",
            "Converted SB-055 (2017-04-24).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-055 (2017-04-24).csv\n",
            "Converted SB-078 (2019-04-17).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-078 (2019-04-17).csv\n",
            "Converted SB-093 (2019-03-19).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-093 (2019-03-19).csv\n",
            "Converted SB-039 (2017-05-31).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-039 (2017-05-31).csv\n",
            "Converted SB-010 (2017-07-24).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-010 (2017-07-24).csv\n",
            "Converted SB-111 (2017-08-28).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-111 (2017-08-28).csv\n",
            "Converted SB-008 (2021-06-30).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-008 (2021-06-30).csv\n",
            "Converted SB-002 (2017-01-29).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-002 (2017-01-29).csv\n",
            "Converted SB-108 (2019-01-16).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-108 (2019-01-16).csv\n",
            "Converted SB-070 (2019-10-16).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-070 (2019-10-16).csv\n",
            "Converted SB-112 (2021-10-29.xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-112 (2021-10-29.csv\n",
            "Converted SB-056 (2020-10-28).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-056 (2020-10-28).csv\n",
            "Converted SB-071 (2018-08-31).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-071 (2018-08-31).csv\n",
            "Converted SB-032 (2017-10-10).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-032 (2017-10-10).csv\n",
            "Converted SB-079 (2021-12-30).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-079 (2021-12-30).csv\n",
            "Converted SB-014 (2022-01-10).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-014 (2022-01-10).csv\n",
            "Converted SB-120 (2018-07-18).xlsx to CSV at /content/drive/My Drive/Patient data individual/2024-Data/csv files/SB-120 (2018-07-18).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-001 (2020-02-05).csv: 0 rows\n",
            "Processed SB-001 (2020-02-05).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-001 (2020-02-05).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-059 (2021-10-06).csv: 0 rows\n",
            "Processed SB-059 (2021-10-06).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-059 (2021-10-06).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-026 (2018-02-26).csv: 0 rows\n",
            "Processed SB-026 (2018-02-26).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-026 (2018-02-26).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-035 (2017-09-11).csv: 0 rows\n",
            "Processed SB-035 (2017-09-11).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-035 (2017-09-11).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-119 (2018-12-17).csv: 0 rows\n",
            "Processed SB-119 (2018-12-17).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-119 (2018-12-17).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-003 (2020-03-29).csv: 0 rows\n",
            "Processed SB-003 (2020-03-29).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-003 (2020-03-29).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-007 (2017-05-15).csv: 0 rows\n",
            "Processed SB-007 (2017-05-15).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-007 (2017-05-15).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-046 (2017-10-11).csv: 0 rows\n",
            "Processed SB-046 (2017-10-11).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-046 (2017-10-11).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-072 (2021-10-18).csv: 0 rows\n",
            "Processed SB-072 (2021-10-18).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-072 (2021-10-18).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-018 (2017-09-13).csv: 0 rows\n",
            "Processed SB-018 (2017-09-13).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-018 (2017-09-13).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-015 (2018-05-20).csv: 0 rows\n",
            "Processed SB-015 (2018-05-20).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-015 (2018-05-20).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-081 (2021-04-05).csv: 0 rows\n",
            "Processed SB-081 (2021-04-05).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-081 (2021-04-05).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-052 (2017-03-08).csv: 0 rows\n",
            "Processed SB-052 (2017-03-08).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-052 (2017-03-08).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-049 (2019-09-23).csv: 0 rows\n",
            "Processed SB-049 (2019-09-23).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-049 (2019-09-23).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-023 (2020-04-06).csv: 0 rows\n",
            "Processed SB-023 (2020-04-06).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-023 (2020-04-06).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-122 (2022-01-19).csv: 0 rows\n",
            "Processed SB-122 (2022-01-19).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-122 (2022-01-19).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-009 (2019-04-09).csv: 0 rows\n",
            "Processed SB-009 (2019-04-09).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-009 (2019-04-09).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-043 (2020-04-01).csv: 0 rows\n",
            "Processed SB-043 (2020-04-01).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-043 (2020-04-01).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-091 (2018-07-31).csv: 0 rows\n",
            "Processed SB-091 (2018-07-31).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-091 (2018-07-31).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-047 (2020-06-08).csv: 0 rows\n",
            "Processed SB-047 (2020-06-08).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-047 (2020-06-08).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-101 (2018-05-28).csv: 0 rows\n",
            "Processed SB-101 (2018-05-28).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-101 (2018-05-28).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-063 (2019-04-21).csv: 0 rows\n",
            "Processed SB-063 (2019-04-21).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-063 (2019-04-21).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-057 (2017-07-20).csv: 0 rows\n",
            "Processed SB-057 (2017-07-20).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-057 (2017-07-20).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-022 (2021-04-30).csv: 0 rows\n",
            "Processed SB-022 (2021-04-30).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-022 (2021-04-30).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-016 (2018-01-31).csv: 0 rows\n",
            "Processed SB-016 (2018-01-31).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-016 (2018-01-31).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-028 (2018-08-08).csv: 0 rows\n",
            "Processed SB-028 (2018-08-08).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-028 (2018-08-08).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-031 (2018-05-15).csv: 0 rows\n",
            "Processed SB-031 (2018-05-15).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-031 (2018-05-15).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-066 (2017-08-14).csv: 0 rows\n",
            "Processed SB-066 (2017-08-14).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-066 (2017-08-14).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-080 (2019-04-27).csv: 0 rows\n",
            "Processed SB-080 (2019-04-27).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-080 (2019-04-27).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-053 (2018-11-06).csv: 0 rows\n",
            "Processed SB-053 (2018-11-06).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-053 (2018-11-06).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-067 (2018-12-17).csv: 0 rows\n",
            "Processed SB-067 (2018-12-17).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-067 (2018-12-17).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-011 (2022-01-19).csv: 0 rows\n",
            "Processed SB-011 (2022-01-19).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-011 (2022-01-19).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-116 (2018-04-02).csv: 0 rows\n",
            "Processed SB-116 (2018-04-02).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-116 (2018-04-02).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-092 (2020-06-30).csv: 0 rows\n",
            "Processed SB-092 (2020-06-30).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-092 (2020-06-30).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-036 (2019-10-13).csv: 0 rows\n",
            "Processed SB-036 (2019-10-13).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-036 (2019-10-13).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-005 (2017-03-11).csv: 0 rows\n",
            "Processed SB-005 (2017-03-11).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-005 (2017-03-11).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-064 (2020-05-10).csv: 0 rows\n",
            "Processed SB-064 (2020-05-10).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-064 (2020-05-10).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-096 (2020-05-04).csv: 0 rows\n",
            "Processed SB-096 (2020-05-04).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-096 (2020-05-04).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-020 (2017-10-12).csv: 0 rows\n",
            "Processed SB-020 (2017-10-12).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-020 (2017-10-12).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-013 (2017-03-18).csv: 0 rows\n",
            "Processed SB-013 (2017-03-18).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-013 (2017-03-18).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-017 (2021-11-30).csv: 0 rows\n",
            "Processed SB-017 (2021-11-30).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-017 (2021-11-30).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-048 (2021-04-19).csv: 0 rows\n",
            "Processed SB-048 (2021-04-19).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-048 (2021-04-19).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-033 (2020-03-28).csv: 0 rows\n",
            "Processed SB-033 (2020-03-28).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-033 (2020-03-28).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-083 (2018-06-04).csv: 0 rows\n",
            "Processed SB-083 (2018-06-04).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-083 (2018-06-04).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-062 (2017-10-16).csv: 0 rows\n",
            "Processed SB-062 (2017-10-16).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-062 (2017-10-16).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-040 (2021-09-30).csv: 0 rows\n",
            "Processed SB-040 (2021-09-30).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-040 (2021-09-30).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-004 (2021-09-04).csv: 0 rows\n",
            "Processed SB-004 (2021-09-04).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-004 (2021-09-04).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-065 (2017-02-28).csv: 0 rows\n",
            "Processed SB-065 (2017-02-28).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-065 (2017-02-28).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-051 (2017-01-29).csv: 0 rows\n",
            "Processed SB-051 (2017-01-29).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-051 (2017-01-29).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-050 (2018-03-09).csv: 0 rows\n",
            "Processed SB-050 (2018-03-09).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-050 (2018-03-09).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-088 (2021-05-31).csv: 0 rows\n",
            "Processed SB-088 (2021-05-31).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-088 (2021-05-31).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-021 (2017-09-12).csv: 0 rows\n",
            "Processed SB-021 (2017-09-12).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-021 (2017-09-12).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-110 (2019-02-23).csv: 0 rows\n",
            "Processed SB-110 (2019-02-23).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-110 (2019-02-23).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-012 (2018-05-15).csv: 0 rows\n",
            "Processed SB-012 (2018-05-15).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-012 (2018-05-15).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-068 (2021-01-31).csv: 0 rows\n",
            "Processed SB-068 (2021-01-31).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-068 (2021-01-31).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-117 (2019-02-13).csv: 0 rows\n",
            "Processed SB-117 (2019-02-13).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-117 (2019-02-13).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-037 (2018-07-23).csv: 0 rows\n",
            "Processed SB-037 (2018-07-23).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-037 (2018-07-23).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-084 (2021-02-23).csv: 0 rows\n",
            "Processed SB-084 (2021-02-23).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-084 (2021-02-23).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-095 (2021-06-30).csv: 0 rows\n",
            "Processed SB-095 (2021-06-30).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-095 (2021-06-30).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-102 (2016-06-05).csv: 0 rows\n",
            "Processed SB-102 (2016-06-05).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-102 (2016-06-05).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-029 (2020-04-19).csv: 0 rows\n",
            "Processed SB-029 (2020-04-19).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-029 (2020-04-19).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-074 (2017-03-13).csv: 0 rows\n",
            "Processed SB-074 (2017-03-13).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-074 (2017-03-13).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-086 (2017-10-10).csv: 0 rows\n",
            "Processed SB-086 (2017-10-10).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-086 (2017-10-10).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-058 (2021-11-29).csv: 0 rows\n",
            "Processed SB-058 (2021-11-29).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-058 (2021-11-29).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-089 (2021-05-02).csv: 0 rows\n",
            "Processed SB-089 (2021-05-02).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-089 (2021-05-02).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-077 (2018-05-14).csv: 0 rows\n",
            "Processed SB-077 (2018-05-14).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-077 (2018-05-14).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-044 (2019-04-03).csv: 0 rows\n",
            "Processed SB-044 (2019-04-03).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-044 (2019-04-03).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-099 (2018-01-31).csv: 0 rows\n",
            "Processed SB-099 (2018-01-31).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-099 (2018-01-31).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-073 (2021-04-03).csv: 0 rows\n",
            "Processed SB-073 (2021-04-03).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-073 (2021-04-03).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-024 (2017-08-30).csv: 0 rows\n",
            "Processed SB-024 (2017-08-30).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-024 (2017-08-30).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-054 (2017-04-27).csv: 0 rows\n",
            "Processed SB-054 (2017-04-27).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-054 (2017-04-27).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-042 (2019-05-20).csv: 0 rows\n",
            "Processed SB-042 (2019-05-20).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-042 (2019-05-20).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-085 (2020-07-31).csv: 0 rows\n",
            "Processed SB-085 (2020-07-31).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-085 (2020-07-31).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-025 (2019-10-14).csv: 0 rows\n",
            "Processed SB-025 (2019-10-14).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-025 (2019-10-14).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-060 (2018-02-25).csv: 0 rows\n",
            "Processed SB-060 (2018-02-25).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-060 (2018-02-25).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-082 (2019-03-11).csv: 0 rows\n",
            "Processed SB-082 (2019-03-11).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-082 (2019-03-11).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-121 (2019-07-15).csv: 0 rows\n",
            "Processed SB-121 (2019-07-15).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-121 (2019-07-15).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-115 (2020-04-29).csv: 0 rows\n",
            "Processed SB-115 (2020-04-29).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-115 (2020-04-29).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-118 (2018-07-12).csv: 0 rows\n",
            "Processed SB-118 (2018-07-12).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-118 (2018-07-12).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-019 (2018-05-26).csv: 0 rows\n",
            "Processed SB-019 (2018-05-26).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-019 (2018-05-26).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-006 (2020-01-08).csv: 0 rows\n",
            "Processed SB-006 (2020-01-08).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-006 (2020-01-08).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-055 (2017-04-24).csv: 0 rows\n",
            "Processed SB-055 (2017-04-24).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-055 (2017-04-24).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-075 (2019-03-18).csv: 0 rows\n",
            "Processed SB-075 (2019-03-18).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-075 (2019-03-18).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-061 (2017-05-24).csv: 0 rows\n",
            "Processed SB-061 (2017-05-24).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-061 (2017-05-24).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-078 (2019-04-17).csv: 0 rows\n",
            "Processed SB-078 (2019-04-17).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-078 (2019-04-17).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-039 (2017-05-31).csv: 0 rows\n",
            "Processed SB-039 (2017-05-31).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-039 (2017-05-31).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-093 (2019-03-19).csv: 0 rows\n",
            "Processed SB-093 (2019-03-19).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-093 (2019-03-19).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-010 (2017-07-24).csv: 0 rows\n",
            "Processed SB-010 (2017-07-24).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-010 (2017-07-24).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-111 (2017-08-28).csv: 0 rows\n",
            "Processed SB-111 (2017-08-28).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-111 (2017-08-28).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-002 (2017-01-29).csv: 0 rows\n",
            "Processed SB-002 (2017-01-29).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-002 (2017-01-29).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-008 (2021-06-30).csv: 0 rows\n",
            "Processed SB-008 (2021-06-30).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-008 (2021-06-30).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-108 (2019-01-16).csv: 0 rows\n",
            "Processed SB-108 (2019-01-16).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-108 (2019-01-16).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-070 (2019-10-16).csv: 0 rows\n",
            "Processed SB-070 (2019-10-16).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-070 (2019-10-16).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-112 (2021-10-29.csv: 0 rows\n",
            "Processed SB-112 (2021-10-29.csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-112 (2021-10-29.csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-056 (2020-10-28).csv: 0 rows\n",
            "Processed SB-056 (2020-10-28).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-056 (2020-10-28).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-071 (2018-08-31).csv: 0 rows\n",
            "Processed SB-071 (2018-08-31).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-071 (2018-08-31).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-032 (2017-10-10).csv: 0 rows\n",
            "Processed SB-032 (2017-10-10).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-032 (2017-10-10).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-079 (2021-12-30).csv: 0 rows\n",
            "Processed SB-079 (2021-12-30).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-079 (2021-12-30).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-014 (2022-01-10).csv: 0 rows\n",
            "Processed SB-014 (2022-01-10).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-014 (2022-01-10).csv\n",
            "Longest consecutive sequence in 'Unnamed: 1' for SB-120 (2018-07-18).csv: 0 rows\n",
            "Processed SB-120 (2018-07-18).csv and saved without specified columns at /content/drive/My Drive/Patient data individual/2024-Data/processed_csv/SB-120 (2018-07-18).csv\n",
            "All Excel files have been converted and processed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define the folder where your processed CSV files are located\n",
        "processed_csv_folder = '/content/drive/My Drive/Patient data individual/2024-Data/processed_csv'  # Ensure this path is correct\n",
        "\n",
        "# List to store results\n",
        "results = []\n",
        "\n",
        "# Loop through each CSV file in the folder\n",
        "for file_name in os.listdir(processed_csv_folder):\n",
        "    if file_name.endswith('.csv'):\n",
        "        # Construct the full file path\n",
        "        file_path = os.path.join(processed_csv_folder, file_name)\n",
        "\n",
        "        # Read the CSV file\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        # Check if 'PEFR' column exists in the DataFrame\n",
        "        if 'PEFR' in df.columns:\n",
        "            # Check if 'PEFR' values are not integers and convert them if necessary\n",
        "            if not pd.api.types.is_integer_dtype(df['PEFR']):\n",
        "                df['PEFR'] = pd.to_numeric(df['PEFR'], errors='coerce')\n",
        "\n",
        "            # Fill NaN values with the mean of the 'PEFR' column\n",
        "            df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
        "\n",
        "            # Convert 'PEFR' column to integer type, handling non-finite values\n",
        "            df['PEFR'] = df['PEFR'].round().astype('Int64')\n",
        "\n",
        "            # Calculate the average and standard deviation of the 'PEFR' column\n",
        "            average_pefr = df['PEFR'].mean()\n",
        "            std_dev_pefr = df['PEFR'].std()\n",
        "\n",
        "            # Append the result with the file name, average, and standard deviation of PEFR\n",
        "            results.append({'File Name': str(file_name), 'Average PEFR': average_pefr, 'Standard Deviation PEFR': std_dev_pefr})\n",
        "\n",
        "            # Optionally, save the updated DataFrame back to the same file if you want to retain the filled values\n",
        "            # df.to_csv(file_path, index=False)\n",
        "        else:\n",
        "            print(f\"'PEFR' column not found in {file_name}\")\n",
        "\n",
        "# Convert results to a DataFrame and save as a new CSV file\n",
        "results_df = pd.DataFrame(results)\n",
        "output_csv_path = '/content/drive/My Drive/Patient data individual/2024-Data/Summary.csv'\n",
        "results_df.to_csv(output_csv_path, index=False)\n",
        "print(f\"Summary CSV with averages and standard deviations saved to {output_csv_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrYVjanxshT2",
        "outputId": "aa9a11ef-e38e-474d-d553-e310f8314cd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'PEFR' column not found in SB-001 (2020-02-05).csv\n",
            "'PEFR' column not found in SB-007 (2017-05-15).csv\n",
            "'PEFR' column not found in SB-072 (2021-10-18).csv\n",
            "'PEFR' column not found in SB-015 (2018-05-20).csv\n",
            "'PEFR' column not found in SB-049 (2019-09-23).csv\n",
            "'PEFR' column not found in SB-023 (2020-04-06).csv\n",
            "'PEFR' column not found in SB-009 (2019-04-09).csv\n",
            "'PEFR' column not found in SB-043 (2020-04-01).csv\n",
            "'PEFR' column not found in SB-047 (2020-06-08).csv\n",
            "'PEFR' column not found in SB-057 (2017-07-20).csv\n",
            "'PEFR' column not found in SB-016 (2018-01-31).csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'PEFR' column not found in SB-067 (2018-12-17).csv\n",
            "'PEFR' column not found in SB-011 (2022-01-19).csv\n",
            "'PEFR' column not found in SB-036 (2019-10-13).csv\n",
            "'PEFR' column not found in SB-020 (2017-10-12).csv\n",
            "'PEFR' column not found in SB-017 (2021-11-30).csv\n",
            "'PEFR' column not found in SB-062 (2017-10-16).csv\n",
            "'PEFR' column not found in SB-040 (2021-09-30).csv\n",
            "'PEFR' column not found in SB-004 (2021-09-04).csv\n",
            "'PEFR' column not found in SB-065 (2017-02-28).csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'PEFR' column not found in SB-068 (2021-01-31).csv\n",
            "'PEFR' column not found in SB-029 (2020-04-19).csv\n",
            "'PEFR' column not found in SB-074 (2017-03-13).csv\n",
            "'PEFR' column not found in SB-058 (2021-11-29).csv\n",
            "'PEFR' column not found in SB-073 (2021-04-03).csv\n",
            "'PEFR' column not found in SB-054 (2017-04-27).csv\n",
            "'PEFR' column not found in SB-042 (2019-05-20).csv\n",
            "'PEFR' column not found in SB-025 (2019-10-14).csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'PEFR' column not found in SB-006 (2020-01-08).csv\n",
            "'PEFR' column not found in SB-075 (2019-03-18).csv\n",
            "'PEFR' column not found in SB-061 (2017-05-24).csv\n",
            "'PEFR' column not found in SB-039 (2017-05-31).csv\n",
            "'PEFR' column not found in SB-010 (2017-07-24).csv\n",
            "'PEFR' column not found in SB-002 (2017-01-29).csv\n",
            "'PEFR' column not found in SB-008 (2021-06-30).csv\n",
            "'PEFR' column not found in SB-070 (2019-10-16).csv\n",
            "'PEFR' column not found in SB-071 (2018-08-31).csv\n",
            "Summary CSV with averages and standard deviations saved to /content/drive/My Drive/Patient data individual/2024-Data/Summary.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n",
            "<ipython-input-10-8695817cc334>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['PEFR'].fillna(df['PEFR'].mean(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define the folder where your processed CSV files are located\n",
        "processed_csv_folder = '/content/drive/My Drive/Patient data individual/2024-Data/processed_csv'  # Ensure this path is correct\n",
        "\n",
        "# List to store results\n",
        "results = []\n",
        "\n",
        "# Loop through each CSV file in the folder\n",
        "for file_name in os.listdir(processed_csv_folder):\n",
        "    if file_name.endswith('.csv'):\n",
        "        # Construct the full file path\n",
        "        file_path = os.path.join(processed_csv_folder, file_name)\n",
        "\n",
        "        # Read the CSV file\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        # Check if 'PEFR' column exists in the DataFrame\n",
        "        if 'C. PEFR' in df.columns:\n",
        "            # Check if 'PEFR' values are not integers and convert them if necessary\n",
        "            if not pd.api.types.is_integer_dtype(df['C. PEFR']):\n",
        "                df['C. PEFR'] = pd.to_numeric(df['C. PEFR'], errors='coerce')\n",
        "\n",
        "            # Fill NaN values with the mean of the 'PEFR' column\n",
        "            df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
        "\n",
        "            # Convert 'PEFR' column to integer type, handling non-finite values\n",
        "            df['C. PEFR'] = df['C. PEFR'].round().astype('Int64')\n",
        "\n",
        "            # Calculate the average and standard deviation of the 'PEFR' column\n",
        "            average_pefr = df['C. PEFR'].mean()\n",
        "            std_dev_pefr = df['C. PEFR'].std()\n",
        "\n",
        "            # Append the result with the file name, average, and standard deviation of PEFR\n",
        "            results.append({'File Name': str(file_name), 'Average PEFR': average_pefr, 'Standard Deviation PEFR': std_dev_pefr})\n",
        "\n",
        "            # Optionally, save the updated DataFrame back to the same file if you want to retain the filled values\n",
        "            # df.to_csv(file_path, index=False)\n",
        "        else:\n",
        "            print(f\"'PEFR' column not found in {file_name}\")\n",
        "\n",
        "# Convert results to a DataFrame and save as a new CSV file\n",
        "results_df = pd.DataFrame(results)\n",
        "output_csv_path = '/content/drive/My Drive/Patient data individual/2024-Data/Summary2.csv'\n",
        "results_df.to_csv(output_csv_path, index=False)\n",
        "print(f\"Summary CSV with averages and standard deviations saved to {output_csv_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8O2XaMkfQe5_",
        "outputId": "e98ddf8e-6ecf-46a9-8dbc-a8583cc4d841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'PEFR' column not found in SB-059 (2021-10-06).csv\n",
            "'PEFR' column not found in SB-026 (2018-02-26).csv\n",
            "'PEFR' column not found in SB-035 (2017-09-11).csv\n",
            "'PEFR' column not found in SB-119 (2018-12-17).csv\n",
            "'PEFR' column not found in SB-003 (2020-03-29).csv\n",
            "'PEFR' column not found in SB-046 (2017-10-11).csv\n",
            "'PEFR' column not found in SB-018 (2017-09-13).csv\n",
            "'PEFR' column not found in SB-081 (2021-04-05).csv\n",
            "'PEFR' column not found in SB-052 (2017-03-08).csv\n",
            "'PEFR' column not found in SB-122 (2022-01-19).csv\n",
            "'PEFR' column not found in SB-091 (2018-07-31).csv\n",
            "'PEFR' column not found in SB-101 (2018-05-28).csv\n",
            "'PEFR' column not found in SB-063 (2019-04-21).csv\n",
            "'PEFR' column not found in SB-022 (2021-04-30).csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'PEFR' column not found in SB-028 (2018-08-08).csv\n",
            "'PEFR' column not found in SB-031 (2018-05-15).csv\n",
            "'PEFR' column not found in SB-066 (2017-08-14).csv\n",
            "'PEFR' column not found in SB-080 (2019-04-27).csv\n",
            "'PEFR' column not found in SB-053 (2018-11-06).csv\n",
            "'PEFR' column not found in SB-116 (2018-04-02).csv\n",
            "'PEFR' column not found in SB-092 (2020-06-30).csv\n",
            "'PEFR' column not found in SB-005 (2017-03-11).csv\n",
            "'PEFR' column not found in SB-064 (2020-05-10).csv\n",
            "'PEFR' column not found in SB-096 (2020-05-04).csv\n",
            "'PEFR' column not found in SB-013 (2017-03-18).csv\n",
            "'PEFR' column not found in SB-048 (2021-04-19).csv\n",
            "'PEFR' column not found in SB-033 (2020-03-28).csv\n",
            "'PEFR' column not found in SB-083 (2018-06-04).csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'PEFR' column not found in SB-051 (2017-01-29).csv\n",
            "'PEFR' column not found in SB-050 (2018-03-09).csv\n",
            "'PEFR' column not found in SB-088 (2021-05-31).csv\n",
            "'PEFR' column not found in SB-021 (2017-09-12).csv\n",
            "'PEFR' column not found in SB-110 (2019-02-23).csv\n",
            "'PEFR' column not found in SB-012 (2018-05-15).csv\n",
            "'PEFR' column not found in SB-117 (2019-02-13).csv\n",
            "'PEFR' column not found in SB-037 (2018-07-23).csv\n",
            "'PEFR' column not found in SB-084 (2021-02-23).csv\n",
            "'PEFR' column not found in SB-095 (2021-06-30).csv\n",
            "'PEFR' column not found in SB-102 (2016-06-05).csv\n",
            "'PEFR' column not found in SB-086 (2017-10-10).csv\n",
            "'PEFR' column not found in SB-089 (2021-05-02).csv\n",
            "'PEFR' column not found in SB-077 (2018-05-14).csv\n",
            "'PEFR' column not found in SB-044 (2019-04-03).csv\n",
            "'PEFR' column not found in SB-099 (2018-01-31).csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'PEFR' column not found in SB-024 (2017-08-30).csv\n",
            "'PEFR' column not found in SB-085 (2020-07-31).csv\n",
            "'PEFR' column not found in SB-060 (2018-02-25).csv\n",
            "'PEFR' column not found in SB-082 (2019-03-11).csv\n",
            "'PEFR' column not found in SB-121 (2019-07-15).csv\n",
            "'PEFR' column not found in SB-115 (2020-04-29).csv\n",
            "'PEFR' column not found in SB-118 (2018-07-12).csv\n",
            "'PEFR' column not found in SB-019 (2018-05-26).csv\n",
            "'PEFR' column not found in SB-055 (2017-04-24).csv\n",
            "'PEFR' column not found in SB-078 (2019-04-17).csv\n",
            "'PEFR' column not found in SB-093 (2019-03-19).csv\n",
            "'PEFR' column not found in SB-111 (2017-08-28).csv\n",
            "'PEFR' column not found in SB-108 (2019-01-16).csv\n",
            "'PEFR' column not found in SB-112 (2021-10-29.csv\n",
            "'PEFR' column not found in SB-056 (2020-10-28).csv\n",
            "'PEFR' column not found in SB-032 (2017-10-10).csv\n",
            "'PEFR' column not found in SB-079 (2021-12-30).csv\n",
            "'PEFR' column not found in SB-014 (2022-01-10).csv\n",
            "'PEFR' column not found in SB-120 (2018-07-18).csv\n",
            "Summary CSV with averages and standard deviations saved to /content/drive/My Drive/Patient data individual/2024-Data/Summary2.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n",
            "<ipython-input-12-8aa391763273>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['C. PEFR'].fillna(df['C. PEFR'].mean(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install meteostat\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTXbGlygdgE3",
        "outputId": "4c051fc4-4838-428d-ac25-a3d620f8060b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting meteostat\n",
            "  Downloading meteostat-1.6.8-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: pandas>=1.1 in /usr/local/lib/python3.10/dist-packages (from meteostat) (2.2.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from meteostat) (2024.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from meteostat) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1->meteostat) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1->meteostat) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1->meteostat) (1.16.0)\n",
            "Downloading meteostat-1.6.8-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: meteostat\n",
            "Successfully installed meteostat-1.6.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openmeteo-requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QomJ79Bdzbs6",
        "outputId": "80374fe1-71b3-425b-bdf4-b9d338b5bd5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openmeteo-requests in /usr/local/lib/python3.10/dist-packages (1.3.0)\n",
            "Requirement already satisfied: openmeteo-sdk>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from openmeteo-requests) (1.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openmeteo-requests) (2.32.3)\n",
            "Requirement already satisfied: flatbuffers>=24.0.0 in /usr/local/lib/python3.10/dist-packages (from openmeteo-sdk>=1.4.0->openmeteo-requests) (24.3.25)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->openmeteo-requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openmeteo-requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->openmeteo-requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->openmeteo-requests) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests_cache\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gda4Q5-yz0Wa",
        "outputId": "a0d5d883-8acf-4898-b091-59d0f774c176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting requests_cache\n",
            "  Downloading requests_cache-1.2.1-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.10/dist-packages (from requests_cache) (24.2.0)\n",
            "Collecting cattrs>=22.2 (from requests_cache)\n",
            "  Downloading cattrs-24.1.2-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests_cache) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.22 in /usr/local/lib/python3.10/dist-packages (from requests_cache) (2.32.3)\n",
            "Collecting url-normalize>=1.4 (from requests_cache)\n",
            "  Downloading url_normalize-1.4.3-py2.py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: urllib3>=1.25.5 in /usr/local/lib/python3.10/dist-packages (from requests_cache) (2.2.3)\n",
            "Requirement already satisfied: exceptiongroup>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests_cache) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions!=4.6.3,>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests_cache) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22->requests_cache) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22->requests_cache) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22->requests_cache) (2024.8.30)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from url-normalize>=1.4->requests_cache) (1.16.0)\n",
            "Downloading requests_cache-1.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/61.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cattrs-24.1.2-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading url_normalize-1.4.3-py2.py3-none-any.whl (6.8 kB)\n",
            "Installing collected packages: url-normalize, cattrs, requests_cache\n",
            "Successfully installed cattrs-24.1.2 requests_cache-1.2.1 url-normalize-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install retry-requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TbEFwjAz6IG",
        "outputId": "7f315598-0776-43b4-c744-659314887ff7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting retry-requests\n",
            "  Downloading retry_requests-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from retry-requests) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.10/dist-packages (from retry-requests) (2.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->retry-requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->retry-requests) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->retry-requests) (2024.8.30)\n",
            "Downloading retry_requests-2.0.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: retry-requests\n",
            "Successfully installed retry-requests-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openmeteo_requests\n",
        "import requests_cache\n",
        "import pandas as pd\n",
        "from retry_requests import retry\n",
        "import numpy as np\n",
        "\n",
        "# Setup the Open-Meteo API client with caching and retry functionality\n",
        "cache_session = requests_cache.CachedSession('.cache', expire_after=3600)\n",
        "retry_session = retry(cache_session, retries=5, backoff_factor=0.2)\n",
        "openmeteo = openmeteo_requests.Client(session=retry_session)\n",
        "\n",
        "def fetch_weather_data(latitude, longitude, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Fetch hourly temperature data for a given latitude, longitude, and date range.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Define Open-Meteo API endpoint and parameters\n",
        "        url = \"https://historical-forecast-api.open-meteo.com/v1/forecast\"\n",
        "        params = {\n",
        "            \"latitude\": latitude,\n",
        "            \"longitude\": longitude,\n",
        "            \"start_date\": start_date,\n",
        "            \"end_date\": end_date,\n",
        "            \"hourly\": \"temperature_2m\"\n",
        "        }\n",
        "\n",
        "        # Request data from Open-Meteo API\n",
        "        responses = openmeteo.weather_api(url, params=params)\n",
        "        response = responses[0]\n",
        "\n",
        "        # Debugging: Print raw API response for validation\n",
        "        print(f\"Processing data for location ({latitude}, {longitude})\")\n",
        "        print(f\"Raw API Response: {response}\")\n",
        "\n",
        "        # Extract hourly temperature data\n",
        "        hourly = response.Hourly()\n",
        "        hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()\n",
        "\n",
        "        # Validate the extracted temperature data\n",
        "        if hourly_temperature_2m is None or np.size(hourly_temperature_2m) == 0:\n",
        "            print(f\"No valid temperature data available for location ({latitude}, {longitude})\")\n",
        "            return None, None\n",
        "\n",
        "        # Create a DataFrame for hourly data\n",
        "        hourly_data = {\n",
        "            \"datetime\": pd.date_range(\n",
        "                start=pd.to_datetime(hourly.Time(), unit=\"s\", utc=True),\n",
        "                end=pd.to_datetime(hourly.TimeEnd(), unit=\"s\", utc=True),\n",
        "                freq=pd.Timedelta(seconds=hourly.Interval()),\n",
        "                inclusive=\"left\"\n",
        "            ),\n",
        "            \"temperature_2m\": hourly_temperature_2m\n",
        "        }\n",
        "        hourly_dataframe = pd.DataFrame(data=hourly_data)\n",
        "\n",
        "        # Calculate the mean temperature\n",
        "        mean_temperature = hourly_dataframe[\"temperature_2m\"].mean()\n",
        "        print(f\"Mean temperature for ({latitude}, {longitude}) from {start_date} to {end_date}: {mean_temperature:.2f}°C\")\n",
        "\n",
        "        return mean_temperature, hourly_dataframe\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching weather data for ({latitude}, {longitude}): {e}\")\n",
        "        return None, None\n",
        "\n",
        "def process_multiple_locations(input_csv, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Process multiple locations from a CSV file and fetch mean temperature data.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load location data from CSV\n",
        "        locations = pd.read_csv(input_csv)\n",
        "        locations = locations.dropna(subset=['latitude', 'longitude'])  # Drop rows with missing data\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File '{input_csv}' not found.\")\n",
        "        return None\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Iterate through each location in the DataFrame\n",
        "    for index, row in locations.iterrows():\n",
        "        latitude = row[\"latitude\"]\n",
        "        longitude = row[\"longitude\"]\n",
        "        print(f\"Fetching weather data for location {index + 1}: ({latitude}, {longitude})\")\n",
        "\n",
        "        # Fetch weather data for the location\n",
        "        mean_temp, _ = fetch_weather_data(latitude, longitude, start_date, end_date)\n",
        "\n",
        "        # Append results to the list\n",
        "        results.append({\n",
        "            \"latitude\": latitude,\n",
        "            \"longitude\": longitude,\n",
        "            \"mean_temperature\": mean_temp\n",
        "        })\n",
        "\n",
        "    # Create a DataFrame from the results\n",
        "    results_df = pd.DataFrame(results)\n",
        "    return results_df\n",
        "\n",
        "# Main execution block\n",
        "if __name__ == \"__main__\":\n",
        "    # Input and output CSV file paths\n",
        "    input_csv = \"/content/drive/My Drive/Patient data individual/2024-Data/data_with_latitude_altitude.csv\"  # Replace with your file path\n",
        "    output_csv = \"/content/drive/My Drive/Patient data individual/2024-Data/mean_temperature_results.csv\"\n",
        "\n",
        "    # Define the date range for historical weather data\n",
        "    start_date = \"2016-01-01\"  # Start date in YYYY-MM-DD format\n",
        "    end_date = \"2019-12-31\"  # End date in YYYY-MM-DD format\n",
        "\n",
        "    # Process all locations and get a DataFrame with results\n",
        "    results_df = process_multiple_locations(input_csv, start_date, end_date)\n",
        "\n",
        "    # Save results to a CSV file\n",
        "    if results_df is not None:\n",
        "        results_df.to_csv(output_csv, index=False)\n",
        "        print(f\"Results saved to '{output_csv}'\")\n",
        "    else:\n",
        "        print(\"No results to save.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb9Y528hQ4bH",
        "outputId": "2e9f5c30-4716-409a-cf82-bd2862b02005"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching weather data for location 1: (37.350559, 126.741605)\n",
            "Processing data for location (37.350559, 126.741605)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3fd0>\n",
            "Mean temperature for (37.350559, 126.741605) from 2016-01-01 to 2019-12-31: 11.35°C\n",
            "Fetching weather data for location 2: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3850>\n",
            "Mean temperature for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 11.16°C\n",
            "Fetching weather data for location 3: (37.4745799, 126.6802403)\n",
            "Processing data for location (37.4745799, 126.6802403)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db38b0>\n",
            "Mean temperature for (37.4745799, 126.6802403) from 2016-01-01 to 2019-12-31: 11.28°C\n",
            "Fetching weather data for location 4: (37.5486391, 126.6826642)\n",
            "Processing data for location (37.5486391, 126.6826642)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3fa0>\n",
            "Mean temperature for (37.5486391, 126.6826642) from 2016-01-01 to 2019-12-31: 10.92°C\n",
            "Fetching weather data for location 5: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3730>\n",
            "Mean temperature for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 11.16°C\n",
            "Fetching weather data for location 6: (37.58178, 127.09034)\n",
            "Processing data for location (37.58178, 127.09034)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3d30>\n",
            "Mean temperature for (37.58178, 127.09034) from 2016-01-01 to 2019-12-31: 11.49°C\n",
            "Fetching weather data for location 7: (35.18206, 129.08285)\n",
            "Processing data for location (35.18206, 129.08285)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3e80>\n",
            "Mean temperature for (35.18206, 129.08285) from 2016-01-01 to 2019-12-31: 13.58°C\n",
            "Fetching weather data for location 8: (37.427132, 126.73455)\n",
            "Processing data for location (37.427132, 126.73455)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3940>\n",
            "Mean temperature for (37.427132, 126.73455) from 2016-01-01 to 2019-12-31: 10.84°C\n",
            "Fetching weather data for location 9: (37.5571919, 127.1715893)\n",
            "Processing data for location (37.5571919, 127.1715893)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3c10>\n",
            "Mean temperature for (37.5571919, 127.1715893) from 2016-01-01 to 2019-12-31: 11.02°C\n",
            "Fetching weather data for location 10: (37.52306, 126.74472)\n",
            "Processing data for location (37.52306, 126.74472)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3e80>\n",
            "Mean temperature for (37.52306, 126.74472) from 2016-01-01 to 2019-12-31: 10.99°C\n",
            "Fetching weather data for location 11: (37.52306, 126.74472)\n",
            "Processing data for location (37.52306, 126.74472)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3640>\n",
            "Mean temperature for (37.52306, 126.74472) from 2016-01-01 to 2019-12-31: 10.99°C\n",
            "Fetching weather data for location 12: (37.65639, 126.835)\n",
            "Processing data for location (37.65639, 126.835)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3820>\n",
            "Mean temperature for (37.65639, 126.835) from 2016-01-01 to 2019-12-31: 10.63°C\n",
            "Fetching weather data for location 13: (37.500828, 127.091458)\n",
            "Processing data for location (37.500828, 127.091458)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3a90>\n",
            "Mean temperature for (37.500828, 127.091458) from 2016-01-01 to 2019-12-31: 11.18°C\n",
            "Fetching weather data for location 14: (37.52298, 127.00056)\n",
            "Processing data for location (37.52298, 127.00056)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3940>\n",
            "Mean temperature for (37.52298, 127.00056) from 2016-01-01 to 2019-12-31: 11.28°C\n",
            "Fetching weather data for location 15: (37.48351, 126.61954)\n",
            "Processing data for location (37.48351, 126.61954)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3e80>\n",
            "Mean temperature for (37.48351, 126.61954) from 2016-01-01 to 2019-12-31: 11.86°C\n",
            "Fetching weather data for location 16: (36.63722, 127.48972)\n",
            "Processing data for location (36.63722, 127.48972)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a8c5f9930>\n",
            "Mean temperature for (36.63722, 127.48972) from 2016-01-01 to 2019-12-31: 12.26°C\n",
            "Fetching weather data for location 17: (37.45695, 126.70099)\n",
            "Processing data for location (37.45695, 126.70099)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a7fc0e8c0>\n",
            "Mean temperature for (37.45695, 126.70099) from 2016-01-01 to 2019-12-31: 11.28°C\n",
            "Fetching weather data for location 19: (37.32361, 126.82194)\n",
            "Processing data for location (37.32361, 126.82194)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a8c5f9930>\n",
            "Mean temperature for (37.32361, 126.82194) from 2016-01-01 to 2019-12-31: 11.13°C\n",
            "Fetching weather data for location 20: (37.49518, 126.72007)\n",
            "Processing data for location (37.49518, 126.72007)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a7fc0e8c0>\n",
            "Mean temperature for (37.49518, 126.72007) from 2016-01-01 to 2019-12-31: 10.99°C\n",
            "Fetching weather data for location 21: (37.4610754, 126.6923674)\n",
            "Processing data for location (37.4610754, 126.6923674)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3fd0>\n",
            "Mean temperature for (37.4610754, 126.6923674) from 2016-01-01 to 2019-12-31: 11.28°C\n",
            "Fetching weather data for location 22: (37.5178425, 126.8596694)\n",
            "Processing data for location (37.5178425, 126.8596694)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3d30>\n",
            "Mean temperature for (37.5178425, 126.8596694) from 2016-01-01 to 2019-12-31: 11.55°C\n",
            "Fetching weather data for location 23: (37.6192449, 126.6928683)\n",
            "Processing data for location (37.6192449, 126.6928683)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a8c5fb490>\n",
            "Mean temperature for (37.6192449, 126.6928683) from 2016-01-01 to 2019-12-31: 10.68°C\n",
            "Fetching weather data for location 24: (37.30367, 127.08771)\n",
            "Processing data for location (37.30367, 127.08771)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a8c5fb490>\n",
            "Mean temperature for (37.30367, 127.08771) from 2016-01-01 to 2019-12-31: 10.84°C\n",
            "Fetching weather data for location 25: (37.44435, 126.86499)\n",
            "Processing data for location (37.44435, 126.86499)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3940>\n",
            "Mean temperature for (37.44435, 126.86499) from 2016-01-01 to 2019-12-31: 10.81°C\n",
            "Fetching weather data for location 26: (35.95015, 127.13929)\n",
            "Processing data for location (35.95015, 127.13929)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3730>\n",
            "Mean temperature for (35.95015, 127.13929) from 2016-01-01 to 2019-12-31: 12.42°C\n",
            "Fetching weather data for location 27: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3d30>\n",
            "Mean temperature for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 11.16°C\n",
            "Fetching weather data for location 28: (37.50698, 126.88157)\n",
            "Processing data for location (37.50698, 126.88157)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3e80>\n",
            "Mean temperature for (37.50698, 126.88157) from 2016-01-01 to 2019-12-31: 11.55°C\n",
            "Fetching weather data for location 29: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3b50>\n",
            "Mean temperature for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 11.16°C\n",
            "Fetching weather data for location 30: (37.4793778, 126.7104972)\n",
            "Processing data for location (37.4793778, 126.7104972)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3fa0>\n",
            "Mean temperature for (37.4793778, 126.7104972) from 2016-01-01 to 2019-12-31: 11.16°C\n",
            "Fetching weather data for location 31: (37.4624982, 126.9009081)\n",
            "Processing data for location (37.4624982, 126.9009081)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3c10>\n",
            "Mean temperature for (37.4624982, 126.9009081) from 2016-01-01 to 2019-12-31: 10.81°C\n",
            "Fetching weather data for location 32: (37.52306, 126.74472)\n",
            "Processing data for location (37.52306, 126.74472)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3940>\n",
            "Mean temperature for (37.52306, 126.74472) from 2016-01-01 to 2019-12-31: 10.99°C\n",
            "Fetching weather data for location 33: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3640>\n",
            "Mean temperature for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 11.16°C\n",
            "Fetching weather data for location 34: (37.3191345, 126.9570645)\n",
            "Processing data for location (37.3191345, 126.9570645)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3dc0>\n",
            "Mean temperature for (37.3191345, 126.9570645) from 2016-01-01 to 2019-12-31: 10.84°C\n",
            "Fetching weather data for location 35: (37.4581768, 126.7142625)\n",
            "Processing data for location (37.4581768, 126.7142625)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3b50>\n",
            "Mean temperature for (37.4581768, 126.7142625) from 2016-01-01 to 2019-12-31: 11.28°C\n",
            "Fetching weather data for location 36: (37.3304454, 126.7959133)\n",
            "Processing data for location (37.3304454, 126.7959133)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3e80>\n",
            "Mean temperature for (37.3304454, 126.7959133) from 2016-01-01 to 2019-12-31: 11.14°C\n",
            "Fetching weather data for location 37: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3730>\n",
            "Mean temperature for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 11.16°C\n",
            "Fetching weather data for location 38: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db36a0>\n",
            "Mean temperature for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 11.16°C\n",
            "Fetching weather data for location 39: (37.44435, 126.86499)\n",
            "Processing data for location (37.44435, 126.86499)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3640>\n",
            "Mean temperature for (37.44435, 126.86499) from 2016-01-01 to 2019-12-31: 10.81°C\n",
            "Fetching weather data for location 40: (37.50905, 127.048)\n",
            "Processing data for location (37.50905, 127.048)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3f40>\n",
            "Mean temperature for (37.50905, 127.048) from 2016-01-01 to 2019-12-31: 11.18°C\n",
            "Fetching weather data for location 41: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db39a0>\n",
            "Mean temperature for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 11.16°C\n",
            "Fetching weather data for location 42: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3940>\n",
            "Mean temperature for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 11.16°C\n",
            "Fetching weather data for location 43: (37.55233, 126.65543)\n",
            "Processing data for location (37.55233, 126.65543)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3fa0>\n",
            "Mean temperature for (37.55233, 126.65543) from 2016-01-01 to 2019-12-31: 11.58°C\n",
            "Fetching weather data for location 44: (37.65639, 126.835)\n",
            "Processing data for location (37.65639, 126.835)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3e80>\n",
            "Mean temperature for (37.65639, 126.835) from 2016-01-01 to 2019-12-31: 10.63°C\n",
            "Fetching weather data for location 46: (36.5, 127.08333)\n",
            "Processing data for location (36.5, 127.08333)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3d30>\n",
            "Mean temperature for (36.5, 127.08333) from 2016-01-01 to 2019-12-31: 12.12°C\n",
            "Fetching weather data for location 47: (37.613308, 126.9595175)\n",
            "Processing data for location (37.613308, 126.9595175)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3e80>\n",
            "Mean temperature for (37.613308, 126.9595175) from 2016-01-01 to 2019-12-31: 11.15°C\n",
            "Fetching weather data for location 48: (37.5200818, 126.7451762)\n",
            "Processing data for location (37.5200818, 126.7451762)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3b50>\n",
            "Mean temperature for (37.5200818, 126.7451762) from 2016-01-01 to 2019-12-31: 10.99°C\n",
            "Fetching weather data for location 49: (37.1059636, 128.8779963)\n",
            "Processing data for location (37.1059636, 128.8779963)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3820>\n",
            "Mean temperature for (37.1059636, 128.8779963) from 2016-01-01 to 2019-12-31: 6.98°C\n",
            "Fetching weather data for location 50: (37.5002502, 126.9622625)\n",
            "Processing data for location (37.5002502, 126.9622625)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db36a0>\n",
            "Mean temperature for (37.5002502, 126.9622625) from 2016-01-01 to 2019-12-31: 11.64°C\n",
            "Fetching weather data for location 52: (37.5121297, 126.7851887)\n",
            "Processing data for location (37.5121297, 126.7851887)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3d30>\n",
            "Mean temperature for (37.5121297, 126.7851887) from 2016-01-01 to 2019-12-31: 11.16°C\n",
            "Fetching weather data for location 53: (37.5671607, 126.8538133)\n",
            "Processing data for location (37.5671607, 126.8538133)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3640>\n",
            "Mean temperature for (37.5671607, 126.8538133) from 2016-01-01 to 2019-12-31: 11.52°C\n",
            "Fetching weather data for location 54: (37.4899524, 126.807212)\n",
            "Processing data for location (37.4899524, 126.807212)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db39a0>\n",
            "Mean temperature for (37.4899524, 126.807212) from 2016-01-01 to 2019-12-31: 11.16°C\n",
            "Fetching weather data for location 55: (37.518273, 126.8143472)\n",
            "Processing data for location (37.518273, 126.8143472)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3b50>\n",
            "Mean temperature for (37.518273, 126.8143472) from 2016-01-01 to 2019-12-31: 11.16°C\n",
            "Fetching weather data for location 56: (37.4047607, 126.7181394)\n",
            "Processing data for location (37.4047607, 126.7181394)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3c10>\n",
            "Mean temperature for (37.4047607, 126.7181394) from 2016-01-01 to 2019-12-31: 11.66°C\n",
            "Fetching weather data for location 57: (37.50971, 126.73794)\n",
            "Processing data for location (37.50971, 126.73794)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3f40>\n",
            "Mean temperature for (37.50971, 126.73794) from 2016-01-01 to 2019-12-31: 10.99°C\n",
            "Fetching weather data for location 58: (37.4928083, 126.7240251)\n",
            "Processing data for location (37.4928083, 126.7240251)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3640>\n",
            "Mean temperature for (37.4928083, 126.7240251) from 2016-01-01 to 2019-12-31: 10.99°C\n",
            "Fetching weather data for location 59: (37.4650484, 126.8212728)\n",
            "Processing data for location (37.4650484, 126.8212728)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3d30>\n",
            "Mean temperature for (37.4650484, 126.8212728) from 2016-01-01 to 2019-12-31: 10.70°C\n",
            "Fetching weather data for location 60: (37.4901225, 126.7505015)\n",
            "Processing data for location (37.4901225, 126.7505015)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53e11330>\n",
            "Mean temperature for (37.4901225, 126.7505015) from 2016-01-01 to 2019-12-31: 10.99°C\n",
            "Fetching weather data for location 61: (37.46362, 126.65)\n",
            "Processing data for location (37.46362, 126.65)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3e80>\n",
            "Mean temperature for (37.46362, 126.65) from 2016-01-01 to 2019-12-31: 11.82°C\n",
            "Fetching weather data for location 62: (36.80488, 127.19431)\n",
            "Processing data for location (36.80488, 127.19431)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3640>\n",
            "Mean temperature for (36.80488, 127.19431) from 2016-01-01 to 2019-12-31: 11.77°C\n",
            "Fetching weather data for location 63: (37.2833823, 127.0664811)\n",
            "Processing data for location (37.2833823, 127.0664811)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db36a0>\n",
            "Mean temperature for (37.2833823, 127.0664811) from 2016-01-01 to 2019-12-31: 10.84°C\n",
            "Fetching weather data for location 64: (4.81667, 12.21667)\n",
            "Processing data for location (4.81667, 12.21667)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db38b0>\n",
            "Mean temperature for (4.81667, 12.21667) from 2016-01-01 to 2019-12-31: nan°C\n",
            "Fetching weather data for location 65: (37.4057602, 126.7085013)\n",
            "Processing data for location (37.4057602, 126.7085013)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3dc0>\n",
            "Mean temperature for (37.4057602, 126.7085013) from 2016-01-01 to 2019-12-31: 11.66°C\n",
            "Fetching weather data for location 66: (36.5969032, 126.6629617)\n",
            "Processing data for location (36.5969032, 126.6629617)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3730>\n",
            "Mean temperature for (36.5969032, 126.6629617) from 2016-01-01 to 2019-12-31: 11.98°C\n",
            "Fetching weather data for location 67: (37.4913437, 126.722941)\n",
            "Processing data for location (37.4913437, 126.722941)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3b50>\n",
            "Mean temperature for (37.4913437, 126.722941) from 2016-01-01 to 2019-12-31: 10.99°C\n",
            "Fetching weather data for location 68: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3e80>\n",
            "Mean temperature for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 11.16°C\n",
            "Fetching weather data for location 69: (37.53017, 126.90312)\n",
            "Processing data for location (37.53017, 126.90312)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db38b0>\n",
            "Mean temperature for (37.53017, 126.90312) from 2016-01-01 to 2019-12-31: 11.52°C\n",
            "Fetching weather data for location 70: (37.4906976, 126.723817)\n",
            "Processing data for location (37.4906976, 126.723817)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3d30>\n",
            "Mean temperature for (37.4906976, 126.723817) from 2016-01-01 to 2019-12-31: 10.99°C\n",
            "Fetching weather data for location 71: (37.5176, 126.7953017)\n",
            "Processing data for location (37.5176, 126.7953017)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db39a0>\n",
            "Mean temperature for (37.5176, 126.7953017) from 2016-01-01 to 2019-12-31: 11.16°C\n",
            "Fetching weather data for location 72: (37.562689, 126.680666)\n",
            "Processing data for location (37.562689, 126.680666)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3820>\n",
            "Mean temperature for (37.562689, 126.680666) from 2016-01-01 to 2019-12-31: 10.92°C\n",
            "Fetching weather data for location 73: (37.5341009, 126.7101266)\n",
            "Processing data for location (37.5341009, 126.7101266)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3dc0>\n",
            "Mean temperature for (37.5341009, 126.7101266) from 2016-01-01 to 2019-12-31: 10.92°C\n",
            "Fetching weather data for location 74: (37.4926282, 126.74998)\n",
            "Processing data for location (37.4926282, 126.74998)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3730>\n",
            "Mean temperature for (37.4926282, 126.74998) from 2016-01-01 to 2019-12-31: 10.99°C\n",
            "Fetching weather data for location 75: (37.47876, 126.95235)\n",
            "Error fetching weather data for (37.47876, 126.95235): {'error': True, 'reason': 'Minutely API request limit exceeded. Please try again in one minute.'}\n",
            "Fetching weather data for location 76: (37.45767, 126.88212)\n",
            "Error fetching weather data for (37.45767, 126.88212): {'reason': 'Minutely API request limit exceeded. Please try again in one minute.', 'error': True}\n",
            "Fetching weather data for location 77: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3850>\n",
            "Mean temperature for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 11.16°C\n",
            "Fetching weather data for location 78: (38.37945, 128.46755)\n",
            "Error fetching weather data for (38.37945, 128.46755): {'error': True, 'reason': 'Minutely API request limit exceeded. Please try again in one minute.'}\n",
            "Fetching weather data for location 79: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3a90>\n",
            "Mean temperature for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 11.16°C\n",
            "Fetching weather data for location 80: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3dc0>\n",
            "Mean temperature for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 11.16°C\n",
            "Fetching weather data for location 82: (37.43407, 126.99989)\n",
            "Error fetching weather data for (37.43407, 126.99989): {'error': True, 'reason': 'Minutely API request limit exceeded. Please try again in one minute.'}\n",
            "Fetching weather data for location 83: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3820>\n",
            "Mean temperature for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 11.16°C\n",
            "Fetching weather data for location 84: (37.5069745, 126.9138037)\n",
            "Error fetching weather data for (37.5069745, 126.9138037): {'error': True, 'reason': 'Minutely API request limit exceeded. Please try again in one minute.'}\n",
            "Fetching weather data for location 85: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3f40>\n",
            "Mean temperature for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 11.16°C\n",
            "Fetching weather data for location 86: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db36a0>\n",
            "Mean temperature for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 11.16°C\n",
            "Fetching weather data for location 87: (36.28071, 127.34533)\n",
            "Error fetching weather data for (36.28071, 127.34533): {'reason': 'Minutely API request limit exceeded. Please try again in one minute.', 'error': True}\n",
            "Fetching weather data for location 88: (37.44435, 126.86499)\n",
            "Processing data for location (37.44435, 126.86499)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3e80>\n",
            "Mean temperature for (37.44435, 126.86499) from 2016-01-01 to 2019-12-31: 10.81°C\n",
            "Fetching weather data for location 89: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3730>\n",
            "Mean temperature for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 11.16°C\n",
            "Fetching weather data for location 90: (37.5228388, 126.7290431)\n",
            "Error fetching weather data for (37.5228388, 126.7290431): {'error': True, 'reason': 'Minutely API request limit exceeded. Please try again in one minute.'}\n",
            "Fetching weather data for location 91: (37.52261, 126.85678)\n",
            "Error fetching weather data for (37.52261, 126.85678): {'error': True, 'reason': 'Minutely API request limit exceeded. Please try again in one minute.'}\n",
            "Fetching weather data for location 92: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3730>\n",
            "Mean temperature for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 11.16°C\n",
            "Fetching weather data for location 93: (37.53391, 126.9775)\n",
            "Error fetching weather data for (37.53391, 126.9775): {'error': True, 'reason': 'Minutely API request limit exceeded. Please try again in one minute.'}\n",
            "Fetching weather data for location 94: (22.5015, 114.10144)\n",
            "Error fetching weather data for (22.5015, 114.10144): {'error': True, 'reason': 'Minutely API request limit exceeded. Please try again in one minute.'}\n",
            "Fetching weather data for location 95: (37.4031099, 126.7261793)\n",
            "Error fetching weather data for (37.4031099, 126.7261793): {'error': True, 'reason': 'Minutely API request limit exceeded. Please try again in one minute.'}\n",
            "Fetching weather data for location 96: (37.44435, 126.86499)\n",
            "Processing data for location (37.44435, 126.86499)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3640>\n",
            "Mean temperature for (37.44435, 126.86499) from 2016-01-01 to 2019-12-31: 10.81°C\n",
            "Fetching weather data for location 97: (37.4337, 126.72322)\n",
            "Error fetching weather data for (37.4337, 126.72322): {'error': True, 'reason': 'Minutely API request limit exceeded. Please try again in one minute.'}\n",
            "Fetching weather data for location 98: (37.52261, 126.79994)\n",
            "Error fetching weather data for (37.52261, 126.79994): {'error': True, 'reason': 'Minutely API request limit exceeded. Please try again in one minute.'}\n",
            "Fetching weather data for location 99: (37.6, 127.25)\n",
            "Error fetching weather data for (37.6, 127.25): {'error': True, 'reason': 'Minutely API request limit exceeded. Please try again in one minute.'}\n",
            "Fetching weather data for location 100: (37.49518, 126.72007)\n",
            "Processing data for location (37.49518, 126.72007)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3dc0>\n",
            "Mean temperature for (37.49518, 126.72007) from 2016-01-01 to 2019-12-31: 10.99°C\n",
            "Fetching weather data for location 101: (37.4906976, 126.723817)\n",
            "Processing data for location (37.4906976, 126.723817)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3730>\n",
            "Mean temperature for (37.4906976, 126.723817) from 2016-01-01 to 2019-12-31: 10.99°C\n",
            "Fetching weather data for location 102: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3e80>\n",
            "Mean temperature for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 11.16°C\n",
            "Fetching weather data for location 103: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3820>\n",
            "Mean temperature for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 11.16°C\n",
            "Fetching weather data for location 104: (35.2382, 128.6925)\n",
            "Error fetching weather data for (35.2382, 128.6925): {'error': True, 'reason': 'Minutely API request limit exceeded. Please try again in one minute.'}\n",
            "Fetching weather data for location 105: (37.49447, 126.8502)\n",
            "Error fetching weather data for (37.49447, 126.8502): {'error': True, 'reason': 'Minutely API request limit exceeded. Please try again in one minute.'}\n",
            "Fetching weather data for location 106: (37.45023, 126.79908)\n",
            "Error fetching weather data for (37.45023, 126.79908): {'error': True, 'reason': 'Minutely API request limit exceeded. Please try again in one minute.'}\n",
            "Fetching weather data for location 107: (37.557476, 126.738256)\n",
            "Error fetching weather data for (37.557476, 126.738256): {'error': True, 'reason': 'Minutely API request limit exceeded. Please try again in one minute.'}\n",
            "Fetching weather data for location 108: (37.49518, 126.72007)\n",
            "Processing data for location (37.49518, 126.72007)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3850>\n",
            "Mean temperature for (37.49518, 126.72007) from 2016-01-01 to 2019-12-31: 10.99°C\n",
            "Fetching weather data for location 110: (37.5121297, 126.7851887)\n",
            "Processing data for location (37.5121297, 126.7851887)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3fa0>\n",
            "Mean temperature for (37.5121297, 126.7851887) from 2016-01-01 to 2019-12-31: 11.16°C\n",
            "Fetching weather data for location 111: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db36a0>\n",
            "Mean temperature for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 11.16°C\n",
            "Fetching weather data for location 112: (22.19516, 113.53844)\n",
            "Error fetching weather data for (22.19516, 113.53844): {'error': True, 'reason': 'Minutely API request limit exceeded. Please try again in one minute.'}\n",
            "Fetching weather data for location 113: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3730>\n",
            "Mean temperature for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 11.16°C\n",
            "Fetching weather data for location 114: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7a7a53db3b50>\n",
            "Mean temperature for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 11.16°C\n",
            "Results saved to '/content/drive/My Drive/Patient data individual/2024-Data/mean_temperature_results.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openmeteo-requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOSg-8_EwJ8c",
        "outputId": "d0294281-c622-426d-8f36-0e6aa6e47291"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openmeteo-requests\n",
            "  Downloading openmeteo_requests-1.3.0-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting openmeteo-sdk>=1.4.0 (from openmeteo-requests)\n",
            "  Downloading openmeteo_sdk-1.18.0-py3-none-any.whl.metadata (934 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openmeteo-requests) (2.32.3)\n",
            "Requirement already satisfied: flatbuffers>=24.0.0 in /usr/local/lib/python3.10/dist-packages (from openmeteo-sdk>=1.4.0->openmeteo-requests) (24.3.25)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->openmeteo-requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openmeteo-requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->openmeteo-requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->openmeteo-requests) (2024.8.30)\n",
            "Downloading openmeteo_requests-1.3.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading openmeteo_sdk-1.18.0-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: openmeteo-sdk, openmeteo-requests\n",
            "Successfully installed openmeteo-requests-1.3.0 openmeteo-sdk-1.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests_cache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeId5LKGwN1O",
        "outputId": "43c6d233-b31a-4f47-dcdb-0fbd60089373"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting requests_cache\n",
            "  Downloading requests_cache-1.2.1-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.10/dist-packages (from requests_cache) (24.2.0)\n",
            "Collecting cattrs>=22.2 (from requests_cache)\n",
            "  Downloading cattrs-24.1.2-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests_cache) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.22 in /usr/local/lib/python3.10/dist-packages (from requests_cache) (2.32.3)\n",
            "Collecting url-normalize>=1.4 (from requests_cache)\n",
            "  Downloading url_normalize-1.4.3-py2.py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: urllib3>=1.25.5 in /usr/local/lib/python3.10/dist-packages (from requests_cache) (2.2.3)\n",
            "Requirement already satisfied: exceptiongroup>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests_cache) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions!=4.6.3,>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests_cache) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22->requests_cache) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22->requests_cache) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22->requests_cache) (2024.8.30)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from url-normalize>=1.4->requests_cache) (1.16.0)\n",
            "Downloading requests_cache-1.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/61.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cattrs-24.1.2-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading url_normalize-1.4.3-py2.py3-none-any.whl (6.8 kB)\n",
            "Installing collected packages: url-normalize, cattrs, requests_cache\n",
            "Successfully installed cattrs-24.1.2 requests_cache-1.2.1 url-normalize-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install retry-requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aqj4pRHQwUgB",
        "outputId": "358208ba-4e24-4aa1-a136-3e7d22f2838c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting retry-requests\n",
            "  Downloading retry_requests-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from retry-requests) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.10/dist-packages (from retry-requests) (2.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->retry-requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->retry-requests) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->retry-requests) (2024.8.30)\n",
            "Downloading retry_requests-2.0.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: retry-requests\n",
            "Successfully installed retry-requests-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openmeteo_requests\n",
        "import requests_cache\n",
        "import pandas as pd\n",
        "from retry_requests import retry\n",
        "import numpy as np\n",
        "\n",
        "# Setup the Open-Meteo API client with caching and retry functionality\n",
        "cache_session = requests_cache.CachedSession('.cache', expire_after=3600)\n",
        "retry_session = retry(cache_session, retries=5, backoff_factor=0.2)\n",
        "openmeteo = openmeteo_requests.Client(session=retry_session)\n",
        "\n",
        "def fetch_humidity_data(latitude, longitude, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Fetch hourly humidity data for a given latitude, longitude, and date range.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Define Open-Meteo API endpoint and parameters\n",
        "        url = \"https://historical-forecast-api.open-meteo.com/v1/forecast\"\n",
        "        params = {\n",
        "            \"latitude\": latitude,\n",
        "            \"longitude\": longitude,\n",
        "            \"start_date\": start_date,\n",
        "            \"end_date\": end_date,\n",
        "            \"hourly\": \"relative_humidity_2m\"  # Request only humidity data\n",
        "        }\n",
        "\n",
        "        # Request data from Open-Meteo API\n",
        "        responses = openmeteo.weather_api(url, params=params)\n",
        "        response = responses[0]\n",
        "\n",
        "        # Debugging: Print raw API response for validation\n",
        "        print(f\"Processing data for location ({latitude}, {longitude})\")\n",
        "        print(f\"Raw API Response: {response}\")\n",
        "\n",
        "        # Extract hourly humidity data\n",
        "        hourly = response.Hourly()\n",
        "        hourly_humidity_2m = hourly.Variables(0).ValuesAsNumpy()\n",
        "\n",
        "        # Validate the extracted data\n",
        "        if hourly_humidity_2m is None or np.size(hourly_humidity_2m) == 0:\n",
        "            print(f\"No valid humidity data available for location ({latitude}, {longitude})\")\n",
        "            return None, None\n",
        "\n",
        "        # Create a DataFrame for hourly data\n",
        "        hourly_data = {\n",
        "            \"datetime\": pd.date_range(\n",
        "                start=pd.to_datetime(hourly.Time(), unit=\"s\", utc=True),\n",
        "                end=pd.to_datetime(hourly.TimeEnd(), unit=\"s\", utc=True),\n",
        "                freq=pd.Timedelta(seconds=hourly.Interval()),\n",
        "                inclusive=\"left\"\n",
        "            ),\n",
        "            \"humidity_2m\": hourly_humidity_2m\n",
        "        }\n",
        "        hourly_dataframe = pd.DataFrame(data=hourly_data)\n",
        "\n",
        "        # Calculate the mean humidity\n",
        "        mean_humidity = hourly_dataframe[\"humidity_2m\"].mean()\n",
        "        print(f\"Mean humidity for ({latitude}, {longitude}) from {start_date} to {end_date}: {mean_humidity:.2f}%\")\n",
        "\n",
        "        return mean_humidity, hourly_dataframe\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching humidity data for ({latitude}, {longitude}): {e}\")\n",
        "        return None, None\n",
        "\n",
        "def process_multiple_locations(input_csv, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Process multiple locations from a CSV file and fetch mean humidity data.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load location data from CSV\n",
        "        locations = pd.read_csv(input_csv)\n",
        "        locations = locations.dropna(subset=['latitude', 'longitude'])  # Drop rows with missing data\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File '{input_csv}' not found.\")\n",
        "        return None\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Iterate through each location in the DataFrame\n",
        "    for index, row in locations.iterrows():\n",
        "        latitude = row[\"latitude\"]\n",
        "        longitude = row[\"longitude\"]\n",
        "        print(f\"Fetching humidity data for location {index + 1}: ({latitude}, {longitude})\")\n",
        "\n",
        "        # Fetch humidity data for the location\n",
        "        mean_humidity, _ = fetch_humidity_data(latitude, longitude, start_date, end_date)\n",
        "\n",
        "        # Append results to the list\n",
        "        results.append({\n",
        "            \"latitude\": latitude,\n",
        "            \"longitude\": longitude,\n",
        "            \"mean_humidity\": mean_humidity\n",
        "        })\n",
        "\n",
        "    # Create a DataFrame from the results\n",
        "    results_df = pd.DataFrame(results)\n",
        "    return results_df\n",
        "\n",
        "# Main execution block\n",
        "if __name__ == \"__main__\":\n",
        "    # Input and output CSV file paths\n",
        "    input_csv = \"/content/drive/My Drive/Patient data individual/2024-Data/mean_temperature_results.csv\"  # Replace with your file path\n",
        "    output_csv = \"/content/drive/My Drive/Patient data individual/2024-Data/mean_humidity_results.csv\"\n",
        "\n",
        "    # Define the date range for historical weather data\n",
        "    start_date = \"2016-01-01\"  # Start date in YYYY-MM-DD format\n",
        "    end_date = \"2019-12-31\"  # End date in YYYY-MM-DD format\n",
        "\n",
        "    # Process all locations and get a DataFrame with results\n",
        "    results_df = process_multiple_locations(input_csv, start_date, end_date)\n",
        "\n",
        "    # Save results to a CSV file\n",
        "    if results_df is not None:\n",
        "        results_df.to_csv(output_csv, index=False)\n",
        "        print(f\"Results saved to '{output_csv}'\")\n",
        "    else:\n",
        "        print(\"No results to save.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WT-Uw7u_7uj",
        "outputId": "90f5022f-644b-4f80-aafb-032111cd9290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching humidity data for location 1: (37.350559, 126.741605)\n",
            "Processing data for location (37.350559, 126.741605)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f1c730>\n",
            "Mean humidity for (37.350559, 126.741605) from 2016-01-01 to 2019-12-31: 73.50%\n",
            "Fetching humidity data for location 2: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f1cd00>\n",
            "Mean humidity for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 68.82%\n",
            "Fetching humidity data for location 3: (37.4745799, 126.6802403)\n",
            "Processing data for location (37.4745799, 126.6802403)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f1cbe0>\n",
            "Mean humidity for (37.4745799, 126.6802403) from 2016-01-01 to 2019-12-31: 72.08%\n",
            "Fetching humidity data for location 4: (37.5486391, 126.6826642)\n",
            "Processing data for location (37.5486391, 126.6826642)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f1c7f0>\n",
            "Mean humidity for (37.5486391, 126.6826642) from 2016-01-01 to 2019-12-31: 72.40%\n",
            "Fetching humidity data for location 5: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787464d57220>\n",
            "Mean humidity for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 68.82%\n",
            "Fetching humidity data for location 6: (37.58178, 127.09034)\n",
            "Processing data for location (37.58178, 127.09034)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f334f0>\n",
            "Mean humidity for (37.58178, 127.09034) from 2016-01-01 to 2019-12-31: 62.40%\n",
            "Fetching humidity data for location 7: (35.18206, 129.08285)\n",
            "Processing data for location (35.18206, 129.08285)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f304f0>\n",
            "Mean humidity for (35.18206, 129.08285) from 2016-01-01 to 2019-12-31: 66.41%\n",
            "Fetching humidity data for location 8: (37.427132, 126.73455)\n",
            "Processing data for location (37.427132, 126.73455)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f30310>\n",
            "Mean humidity for (37.427132, 126.73455) from 2016-01-01 to 2019-12-31: 72.38%\n",
            "Fetching humidity data for location 9: (37.5571919, 127.1715893)\n",
            "Processing data for location (37.5571919, 127.1715893)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f330a0>\n",
            "Mean humidity for (37.5571919, 127.1715893) from 2016-01-01 to 2019-12-31: 69.01%\n",
            "Fetching humidity data for location 10: (37.52306, 126.74472)\n",
            "Processing data for location (37.52306, 126.74472)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f30730>\n",
            "Mean humidity for (37.52306, 126.74472) from 2016-01-01 to 2019-12-31: 70.12%\n",
            "Fetching humidity data for location 11: (37.52306, 126.74472)\n",
            "Processing data for location (37.52306, 126.74472)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787499bfe7a0>\n",
            "Mean humidity for (37.52306, 126.74472) from 2016-01-01 to 2019-12-31: 70.12%\n",
            "Fetching humidity data for location 12: (37.65639, 126.835)\n",
            "Processing data for location (37.65639, 126.835)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f30580>\n",
            "Mean humidity for (37.65639, 126.835) from 2016-01-01 to 2019-12-31: 72.29%\n",
            "Fetching humidity data for location 13: (37.500828, 127.091458)\n",
            "Processing data for location (37.500828, 127.091458)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f33700>\n",
            "Mean humidity for (37.500828, 127.091458) from 2016-01-01 to 2019-12-31: 68.42%\n",
            "Fetching humidity data for location 14: (37.52298, 127.00056)\n",
            "Processing data for location (37.52298, 127.00056)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f32f80>\n",
            "Mean humidity for (37.52298, 127.00056) from 2016-01-01 to 2019-12-31: 67.08%\n",
            "Fetching humidity data for location 15: (37.48351, 126.61954)\n",
            "Processing data for location (37.48351, 126.61954)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f30370>\n",
            "Mean humidity for (37.48351, 126.61954) from 2016-01-01 to 2019-12-31: 72.46%\n",
            "Fetching humidity data for location 16: (36.63722, 127.48972)\n",
            "Processing data for location (36.63722, 127.48972)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f30850>\n",
            "Mean humidity for (36.63722, 127.48972) from 2016-01-01 to 2019-12-31: 63.85%\n",
            "Fetching humidity data for location 17: (37.45695, 126.70099)\n",
            "Processing data for location (37.45695, 126.70099)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f332e0>\n",
            "Mean humidity for (37.45695, 126.70099) from 2016-01-01 to 2019-12-31: 72.08%\n",
            "Fetching humidity data for location 18: (37.32361, 126.82194)\n",
            "Processing data for location (37.32361, 126.82194)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f33130>\n",
            "Mean humidity for (37.32361, 126.82194) from 2016-01-01 to 2019-12-31: 73.90%\n",
            "Fetching humidity data for location 19: (37.49518, 126.72007)\n",
            "Processing data for location (37.49518, 126.72007)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f33490>\n",
            "Mean humidity for (37.49518, 126.72007) from 2016-01-01 to 2019-12-31: 70.12%\n",
            "Fetching humidity data for location 20: (37.4610754, 126.6923674)\n",
            "Processing data for location (37.4610754, 126.6923674)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f330d0>\n",
            "Mean humidity for (37.4610754, 126.6923674) from 2016-01-01 to 2019-12-31: 72.08%\n",
            "Fetching humidity data for location 21: (37.5178425, 126.8596694)\n",
            "Processing data for location (37.5178425, 126.8596694)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f30910>\n",
            "Mean humidity for (37.5178425, 126.8596694) from 2016-01-01 to 2019-12-31: 64.25%\n",
            "Fetching humidity data for location 22: (37.6192449, 126.6928683)\n",
            "Processing data for location (37.6192449, 126.6928683)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f33520>\n",
            "Mean humidity for (37.6192449, 126.6928683) from 2016-01-01 to 2019-12-31: 73.41%\n",
            "Fetching humidity data for location 23: (37.30367, 127.08771)\n",
            "Processing data for location (37.30367, 127.08771)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f33340>\n",
            "Mean humidity for (37.30367, 127.08771) from 2016-01-01 to 2019-12-31: 69.51%\n",
            "Fetching humidity data for location 24: (37.44435, 126.86499)\n",
            "Processing data for location (37.44435, 126.86499)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f32920>\n",
            "Mean humidity for (37.44435, 126.86499) from 2016-01-01 to 2019-12-31: 70.78%\n",
            "Fetching humidity data for location 25: (35.95015, 127.13929)\n",
            "Processing data for location (35.95015, 127.13929)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f328f0>\n",
            "Mean humidity for (35.95015, 127.13929) from 2016-01-01 to 2019-12-31: 72.68%\n",
            "Fetching humidity data for location 26: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787499b6aa10>\n",
            "Mean humidity for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 68.82%\n",
            "Fetching humidity data for location 27: (37.50698, 126.88157)\n",
            "Processing data for location (37.50698, 126.88157)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f30730>\n",
            "Mean humidity for (37.50698, 126.88157) from 2016-01-01 to 2019-12-31: 64.25%\n",
            "Fetching humidity data for location 28: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787499bfe7a0>\n",
            "Mean humidity for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 68.82%\n",
            "Fetching humidity data for location 29: (37.4793778, 126.7104972)\n",
            "Processing data for location (37.4793778, 126.7104972)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f33460>\n",
            "Mean humidity for (37.4793778, 126.7104972) from 2016-01-01 to 2019-12-31: 71.57%\n",
            "Fetching humidity data for location 30: (37.4624982, 126.9009081)\n",
            "Processing data for location (37.4624982, 126.9009081)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f33400>\n",
            "Mean humidity for (37.4624982, 126.9009081) from 2016-01-01 to 2019-12-31: 70.78%\n",
            "Fetching humidity data for location 31: (37.52306, 126.74472)\n",
            "Processing data for location (37.52306, 126.74472)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787499bfe7a0>\n",
            "Mean humidity for (37.52306, 126.74472) from 2016-01-01 to 2019-12-31: 70.12%\n",
            "Fetching humidity data for location 32: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7874991d7af0>\n",
            "Mean humidity for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 68.82%\n",
            "Fetching humidity data for location 33: (37.3191345, 126.9570645)\n",
            "Processing data for location (37.3191345, 126.9570645)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f30790>\n",
            "Mean humidity for (37.3191345, 126.9570645) from 2016-01-01 to 2019-12-31: 72.04%\n",
            "Fetching humidity data for location 34: (37.4581768, 126.7142625)\n",
            "Processing data for location (37.4581768, 126.7142625)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f32650>\n",
            "Mean humidity for (37.4581768, 126.7142625) from 2016-01-01 to 2019-12-31: 72.08%\n",
            "Fetching humidity data for location 35: (37.3304454, 126.7959133)\n",
            "Processing data for location (37.3304454, 126.7959133)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f30730>\n",
            "Mean humidity for (37.3304454, 126.7959133) from 2016-01-01 to 2019-12-31: 71.98%\n",
            "Fetching humidity data for location 36: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787464d57220>\n",
            "Mean humidity for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 68.82%\n",
            "Fetching humidity data for location 37: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787499b6aa10>\n",
            "Mean humidity for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 68.82%\n",
            "Fetching humidity data for location 38: (37.44435, 126.86499)\n",
            "Processing data for location (37.44435, 126.86499)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7874991d7af0>\n",
            "Mean humidity for (37.44435, 126.86499) from 2016-01-01 to 2019-12-31: 70.78%\n",
            "Fetching humidity data for location 39: (37.50905, 127.048)\n",
            "Processing data for location (37.50905, 127.048)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f32560>\n",
            "Mean humidity for (37.50905, 127.048) from 2016-01-01 to 2019-12-31: 68.42%\n",
            "Fetching humidity data for location 40: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787499bfe7a0>\n",
            "Mean humidity for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 68.82%\n",
            "Fetching humidity data for location 41: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787499b6aa10>\n",
            "Mean humidity for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 68.82%\n",
            "Fetching humidity data for location 42: (37.55233, 126.65543)\n",
            "Processing data for location (37.55233, 126.65543)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f30130>\n",
            "Mean humidity for (37.55233, 126.65543) from 2016-01-01 to 2019-12-31: 74.17%\n",
            "Fetching humidity data for location 43: (37.65639, 126.835)\n",
            "Processing data for location (37.65639, 126.835)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787499b6aa10>\n",
            "Mean humidity for (37.65639, 126.835) from 2016-01-01 to 2019-12-31: 72.29%\n",
            "Fetching humidity data for location 44: (36.5, 127.08333)\n",
            "Processing data for location (36.5, 127.08333)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f32aa0>\n",
            "Mean humidity for (36.5, 127.08333) from 2016-01-01 to 2019-12-31: 69.27%\n",
            "Fetching humidity data for location 45: (37.613308, 126.9595175)\n",
            "Processing data for location (37.613308, 126.9595175)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f32b30>\n",
            "Mean humidity for (37.613308, 126.9595175) from 2016-01-01 to 2019-12-31: 63.98%\n",
            "Fetching humidity data for location 46: (37.5200818, 126.7451762)\n",
            "Processing data for location (37.5200818, 126.7451762)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f33340>\n",
            "Mean humidity for (37.5200818, 126.7451762) from 2016-01-01 to 2019-12-31: 70.12%\n",
            "Fetching humidity data for location 47: (37.1059636, 128.8779963)\n",
            "Processing data for location (37.1059636, 128.8779963)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f32530>\n",
            "Mean humidity for (37.1059636, 128.8779963) from 2016-01-01 to 2019-12-31: 68.21%\n",
            "Fetching humidity data for location 48: (37.5002502, 126.9622625)\n",
            "Processing data for location (37.5002502, 126.9622625)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f32860>\n",
            "Mean humidity for (37.5002502, 126.9622625) from 2016-01-01 to 2019-12-31: 63.29%\n",
            "Fetching humidity data for location 49: (37.5121297, 126.7851887)\n",
            "Processing data for location (37.5121297, 126.7851887)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f33070>\n",
            "Mean humidity for (37.5121297, 126.7851887) from 2016-01-01 to 2019-12-31: 68.82%\n",
            "Fetching humidity data for location 50: (37.5671607, 126.8538133)\n",
            "Processing data for location (37.5671607, 126.8538133)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f32770>\n",
            "Mean humidity for (37.5671607, 126.8538133) from 2016-01-01 to 2019-12-31: 66.38%\n",
            "Fetching humidity data for location 51: (37.4899524, 126.807212)\n",
            "Processing data for location (37.4899524, 126.807212)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787499bfe7a0>\n",
            "Mean humidity for (37.4899524, 126.807212) from 2016-01-01 to 2019-12-31: 68.82%\n",
            "Fetching humidity data for location 52: (37.518273, 126.8143472)\n",
            "Processing data for location (37.518273, 126.8143472)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787464d57220>\n",
            "Mean humidity for (37.518273, 126.8143472) from 2016-01-01 to 2019-12-31: 68.82%\n",
            "Fetching humidity data for location 53: (37.4047607, 126.7181394)\n",
            "Processing data for location (37.4047607, 126.7181394)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787499bfe7a0>\n",
            "Mean humidity for (37.4047607, 126.7181394) from 2016-01-01 to 2019-12-31: 74.23%\n",
            "Fetching humidity data for location 54: (37.50971, 126.73794)\n",
            "Processing data for location (37.50971, 126.73794)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787464d57220>\n",
            "Mean humidity for (37.50971, 126.73794) from 2016-01-01 to 2019-12-31: 70.12%\n",
            "Fetching humidity data for location 55: (37.4928083, 126.7240251)\n",
            "Processing data for location (37.4928083, 126.7240251)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787499bfe7a0>\n",
            "Mean humidity for (37.4928083, 126.7240251) from 2016-01-01 to 2019-12-31: 70.12%\n",
            "Fetching humidity data for location 56: (37.4650484, 126.8212728)\n",
            "Processing data for location (37.4650484, 126.8212728)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787464d57220>\n",
            "Mean humidity for (37.4650484, 126.8212728) from 2016-01-01 to 2019-12-31: 72.06%\n",
            "Fetching humidity data for location 57: (37.4901225, 126.7505015)\n",
            "Processing data for location (37.4901225, 126.7505015)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f32170>\n",
            "Mean humidity for (37.4901225, 126.7505015) from 2016-01-01 to 2019-12-31: 70.12%\n",
            "Fetching humidity data for location 58: (37.46362, 126.65)\n",
            "Processing data for location (37.46362, 126.65)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787464d57220>\n",
            "Mean humidity for (37.46362, 126.65) from 2016-01-01 to 2019-12-31: 71.72%\n",
            "Fetching humidity data for location 59: (36.80488, 127.19431)\n",
            "Processing data for location (36.80488, 127.19431)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7874991d7af0>\n",
            "Mean humidity for (36.80488, 127.19431) from 2016-01-01 to 2019-12-31: 69.19%\n",
            "Fetching humidity data for location 60: (37.2833823, 127.0664811)\n",
            "Processing data for location (37.2833823, 127.0664811)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f322f0>\n",
            "Mean humidity for (37.2833823, 127.0664811) from 2016-01-01 to 2019-12-31: 69.51%\n",
            "Fetching humidity data for location 61: (4.81667, 12.21667)\n",
            "Processing data for location (4.81667, 12.21667)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f32620>\n",
            "Mean humidity for (4.81667, 12.21667) from 2016-01-01 to 2019-12-31: nan%\n",
            "Fetching humidity data for location 62: (37.4057602, 126.7085013)\n",
            "Processing data for location (37.4057602, 126.7085013)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787464d57220>\n",
            "Mean humidity for (37.4057602, 126.7085013) from 2016-01-01 to 2019-12-31: 74.23%\n",
            "Fetching humidity data for location 63: (36.5969032, 126.6629617)\n",
            "Processing data for location (36.5969032, 126.6629617)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f332e0>\n",
            "Mean humidity for (36.5969032, 126.6629617) from 2016-01-01 to 2019-12-31: 72.71%\n",
            "Fetching humidity data for location 64: (37.4913437, 126.722941)\n",
            "Processing data for location (37.4913437, 126.722941)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f32a10>\n",
            "Mean humidity for (37.4913437, 126.722941) from 2016-01-01 to 2019-12-31: 70.12%\n",
            "Fetching humidity data for location 65: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787464d57220>\n",
            "Mean humidity for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 68.82%\n",
            "Fetching humidity data for location 66: (37.53017, 126.90312)\n",
            "Processing data for location (37.53017, 126.90312)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f33160>\n",
            "Mean humidity for (37.53017, 126.90312) from 2016-01-01 to 2019-12-31: 66.38%\n",
            "Fetching humidity data for location 67: (37.4906976, 126.723817)\n",
            "Processing data for location (37.4906976, 126.723817)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f32500>\n",
            "Mean humidity for (37.4906976, 126.723817) from 2016-01-01 to 2019-12-31: 70.12%\n",
            "Fetching humidity data for location 68: (37.5176, 126.7953017)\n",
            "Processing data for location (37.5176, 126.7953017)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f32740>\n",
            "Mean humidity for (37.5176, 126.7953017) from 2016-01-01 to 2019-12-31: 68.82%\n",
            "Fetching humidity data for location 69: (37.562689, 126.680666)\n",
            "Processing data for location (37.562689, 126.680666)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f32320>\n",
            "Mean humidity for (37.562689, 126.680666) from 2016-01-01 to 2019-12-31: 72.40%\n",
            "Fetching humidity data for location 70: (37.5341009, 126.7101266)\n",
            "Processing data for location (37.5341009, 126.7101266)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f30940>\n",
            "Mean humidity for (37.5341009, 126.7101266) from 2016-01-01 to 2019-12-31: 72.40%\n",
            "Fetching humidity data for location 71: (37.4926282, 126.74998)\n",
            "Processing data for location (37.4926282, 126.74998)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f32950>\n",
            "Mean humidity for (37.4926282, 126.74998) from 2016-01-01 to 2019-12-31: 70.12%\n",
            "Fetching humidity data for location 72: (37.47876, 126.95235)\n",
            "Processing data for location (37.47876, 126.95235)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787463f32470>\n",
            "Mean humidity for (37.47876, 126.95235) from 2016-01-01 to 2019-12-31: 63.29%\n",
            "Fetching humidity data for location 73: (37.45767, 126.88212)\n",
            "Error fetching humidity data for (37.45767, 126.88212): {'reason': 'Minutely API request limit exceeded. Please try again in one minute.', 'error': True}\n",
            "Fetching humidity data for location 74: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787464d57220>\n",
            "Mean humidity for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 68.82%\n",
            "Fetching humidity data for location 75: (38.37945, 128.46755)\n",
            "Error fetching humidity data for (38.37945, 128.46755): {'error': True, 'reason': 'Minutely API request limit exceeded. Please try again in one minute.'}\n",
            "Fetching humidity data for location 76: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787499bfe7a0>\n",
            "Mean humidity for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 68.82%\n",
            "Fetching humidity data for location 77: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787464d57220>\n",
            "Mean humidity for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 68.82%\n",
            "Fetching humidity data for location 78: (37.43407, 126.99989)\n",
            "Error fetching humidity data for (37.43407, 126.99989): {'reason': 'Minutely API request limit exceeded. Please try again in one minute.', 'error': True}\n",
            "Fetching humidity data for location 79: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7874991d7af0>\n",
            "Mean humidity for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 68.82%\n",
            "Fetching humidity data for location 80: (37.5069745, 126.9138037)\n",
            "Error fetching humidity data for (37.5069745, 126.9138037): {'error': True, 'reason': 'Minutely API request limit exceeded. Please try again in one minute.'}\n",
            "Fetching humidity data for location 81: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787499bfe7a0>\n",
            "Mean humidity for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 68.82%\n",
            "Fetching humidity data for location 82: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7874991d7af0>\n",
            "Mean humidity for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 68.82%\n",
            "Fetching humidity data for location 83: (36.28071, 127.34533)\n",
            "Error fetching humidity data for (36.28071, 127.34533): {'reason': 'Minutely API request limit exceeded. Please try again in one minute.', 'error': True}\n",
            "Fetching humidity data for location 84: (37.44435, 126.86499)\n",
            "Processing data for location (37.44435, 126.86499)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787464d57220>\n",
            "Mean humidity for (37.44435, 126.86499) from 2016-01-01 to 2019-12-31: 70.78%\n",
            "Fetching humidity data for location 85: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7874991d7af0>\n",
            "Mean humidity for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 68.82%\n",
            "Fetching humidity data for location 86: (37.5228388, 126.7290431)\n",
            "Error fetching humidity data for (37.5228388, 126.7290431): {'error': True, 'reason': 'Minutely API request limit exceeded. Please try again in one minute.'}\n",
            "Fetching humidity data for location 87: (37.52261, 126.85678)\n",
            "Error fetching humidity data for (37.52261, 126.85678): {'reason': 'Minutely API request limit exceeded. Please try again in one minute.', 'error': True}\n",
            "Fetching humidity data for location 88: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787499b6aa10>\n",
            "Mean humidity for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 68.82%\n",
            "Fetching humidity data for location 89: (37.53391, 126.9775)\n",
            "Error fetching humidity data for (37.53391, 126.9775): {'error': True, 'reason': 'Minutely API request limit exceeded. Please try again in one minute.'}\n",
            "Fetching humidity data for location 90: (22.5015, 114.10144)\n",
            "Error fetching humidity data for (22.5015, 114.10144): {'reason': 'Minutely API request limit exceeded. Please try again in one minute.', 'error': True}\n",
            "Fetching humidity data for location 91: (37.4031099, 126.7261793)\n",
            "Error fetching humidity data for (37.4031099, 126.7261793): {'error': True, 'reason': 'Minutely API request limit exceeded. Please try again in one minute.'}\n",
            "Fetching humidity data for location 92: (37.44435, 126.86499)\n",
            "Processing data for location (37.44435, 126.86499)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787499b6aa10>\n",
            "Mean humidity for (37.44435, 126.86499) from 2016-01-01 to 2019-12-31: 70.78%\n",
            "Fetching humidity data for location 93: (37.4337, 126.72322)\n",
            "Error fetching humidity data for (37.4337, 126.72322): {'reason': 'Minutely API request limit exceeded. Please try again in one minute.', 'error': True}\n",
            "Fetching humidity data for location 94: (37.52261, 126.79994)\n",
            "Error fetching humidity data for (37.52261, 126.79994): {'error': True, 'reason': 'Minutely API request limit exceeded. Please try again in one minute.'}\n",
            "Fetching humidity data for location 95: (37.6, 127.25)\n",
            "Error fetching humidity data for (37.6, 127.25): {'reason': 'Minutely API request limit exceeded. Please try again in one minute.', 'error': True}\n",
            "Fetching humidity data for location 96: (37.49518, 126.72007)\n",
            "Processing data for location (37.49518, 126.72007)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787464d57220>\n",
            "Mean humidity for (37.49518, 126.72007) from 2016-01-01 to 2019-12-31: 70.12%\n",
            "Fetching humidity data for location 97: (37.4906976, 126.723817)\n",
            "Processing data for location (37.4906976, 126.723817)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7874991d7af0>\n",
            "Mean humidity for (37.4906976, 126.723817) from 2016-01-01 to 2019-12-31: 70.12%\n",
            "Fetching humidity data for location 98: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787464d57220>\n",
            "Mean humidity for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 68.82%\n",
            "Fetching humidity data for location 99: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7874991d7af0>\n",
            "Mean humidity for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 68.82%\n",
            "Fetching humidity data for location 100: (35.2382, 128.6925)\n",
            "Error fetching humidity data for (35.2382, 128.6925): {'error': True, 'reason': 'Minutely API request limit exceeded. Please try again in one minute.'}\n",
            "Fetching humidity data for location 101: (37.49447, 126.8502)\n",
            "Error fetching humidity data for (37.49447, 126.8502): {'reason': 'Minutely API request limit exceeded. Please try again in one minute.', 'error': True}\n",
            "Fetching humidity data for location 102: (37.45023, 126.79908)\n",
            "Error fetching humidity data for (37.45023, 126.79908): {'error': True, 'reason': 'Minutely API request limit exceeded. Please try again in one minute.'}\n",
            "Fetching humidity data for location 103: (37.557476, 126.738256)\n",
            "Error fetching humidity data for (37.557476, 126.738256): {'reason': 'Minutely API request limit exceeded. Please try again in one minute.', 'error': True}\n",
            "Fetching humidity data for location 104: (37.49518, 126.72007)\n",
            "Processing data for location (37.49518, 126.72007)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787499bfe7a0>\n",
            "Mean humidity for (37.49518, 126.72007) from 2016-01-01 to 2019-12-31: 70.12%\n",
            "Fetching humidity data for location 105: (37.5121297, 126.7851887)\n",
            "Processing data for location (37.5121297, 126.7851887)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787499b6aa10>\n",
            "Mean humidity for (37.5121297, 126.7851887) from 2016-01-01 to 2019-12-31: 68.82%\n",
            "Fetching humidity data for location 106: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787499bfe7a0>\n",
            "Mean humidity for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 68.82%\n",
            "Fetching humidity data for location 107: (22.19516, 113.53844)\n",
            "Error fetching humidity data for (22.19516, 113.53844): {'error': True, 'reason': 'Minutely API request limit exceeded. Please try again in one minute.'}\n",
            "Fetching humidity data for location 108: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x7874991d7af0>\n",
            "Mean humidity for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 68.82%\n",
            "Fetching humidity data for location 109: (37.49889, 126.78306)\n",
            "Processing data for location (37.49889, 126.78306)\n",
            "Raw API Response: <openmeteo_sdk.WeatherApiResponse.WeatherApiResponse object at 0x787499bfe7a0>\n",
            "Mean humidity for (37.49889, 126.78306) from 2016-01-01 to 2019-12-31: 68.82%\n",
            "Results saved to '/content/drive/My Drive/Patient data individual/2024-Data/mean_humidity_results.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "def fetch_aqi(lat, lon):\n",
        "    # Replace this with the actual API URL you are using\n",
        "    url = f\"https://public.opendatasoft.com/api/records/1.0/search/?dataset=openaq&refine.country=KR&geofilter.distance={lat},{lon},10000\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        if data['records']:\n",
        "            # Extracting the AQI or another specific measurement you want\n",
        "            aqi = data['records'][0]['fields'].get('measurements_value', 'No data')\n",
        "            return aqi\n",
        "        else:\n",
        "            return 'No data'\n",
        "    else:\n",
        "        return 'Failed to fetch'\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('/content/updated_matched_data1_manual_v3.csv')\n",
        "\n",
        "# Applying the function to each row and creating a new column with the results\n",
        "data['AQI'] = data.apply(lambda row: fetch_aqi(row['latitude'], row['longitude']), axis=1)\n",
        "\n",
        "# Save the updated dataframe to a new CSV file\n",
        "data.to_csv('updated_data_with_aqi.csv', index=False)"
      ],
      "metadata": {
        "id": "tld2i83kC1Fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Specify the paths to the CSV files\n",
        "average_csv_path = '/content/drive/My Drive/Patient data individual/2024-Data/Summary.csv'\n",
        "data_csv_path = '/content/drive/My Drive/Patient data individual/2024-Data/data_with_latitude_altitude (1).csv'\n",
        "\n",
        "# Step 3: Read the CSV files into pandas DataFrames\n",
        "average_df = pd.read_csv(average_csv_path)\n",
        "data_df = pd.read_csv(data_csv_path)\n",
        "\n",
        "# Step 4: Strip all characters other than the first 6 characters in the 'File Name' column of the average DataFrame\n",
        "average_df['File Name'] = average_df['File Name'].str[:6]\n",
        "\n",
        "# Step 5: Merge the two DataFrames based on matching 'File Name' in average_df and 'ID' in data_df\n",
        "merged_df = pd.merge(data_df, average_df[['File Name', 'Average C.PEFR']], left_on='ID', right_on='File Name', how='left')\n",
        "\n",
        "# Step 6: Create a new output file path\n",
        "directory = '/content/drive/My Drive/Patient data individual/2024-Data/CSV_Files/Preprocessed_dataset'\n",
        "os.makedirs(directory, exist_ok=True)\n",
        "output_csv_path = os.path.join(directory, 'matched_data.csv')\n",
        "\n",
        "# Step 7: Save the updated DataFrame to a new CSV file\n",
        "merged_df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "print(f\"Matched data CSV file has been saved as '{output_csv_path}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fT1XHYF56lAp",
        "outputId": "3933fa90-7a9b-480a-b749-d36c321b10de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matched data CSV file has been saved as '/content/drive/My Drive/Patient data individual/2024-Data/CSV_Files/Preprocessed_dataset/matched_data.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data= pd.read_csv('/content/drive/My Drive/Patient data individual/2024-Data/CSV_Files/Preprocessed_dataset/matched_data.csv')"
      ],
      "metadata": {
        "id": "AGoavTZz_yuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "gqwU4E5jAgKZ",
        "outputId": "81254a40-2192-4a1b-d502-fa9177d80450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0      ID     BCODE       UID1  Age Sex Smoke  Smoke_amount  \\\n",
              "0           0  SB-001  14631875  BC4386476   43   M    NS             0   \n",
              "1           1  SB-002  14010074  BC3298156   66   M    NS             0   \n",
              "2           2  SB-003  14221420  BC4165314   61   M    ES            20   \n",
              "3           3  SB-004  14010592  BC4201070   49   M    NS             0   \n",
              "4           4  SB-005  14010759  BC4212692   53   M    NS             0   \n",
              "\n",
              "   Height  Weight  ...  Smoking_intensity   latitude   longitude altitude  \\\n",
              "0     156      76  ...         Non-smoker  47.275410    8.489700    749.0   \n",
              "1     163      58  ...         Non-smoker  37.498890  126.783060     15.0   \n",
              "2     173      67  ...       Light smoker  37.474580  126.680240     10.0   \n",
              "3     142      51  ...         Non-smoker  37.548639  126.682664     38.0   \n",
              "4     156      70  ...         Non-smoker  37.498890  126.783060     15.0   \n",
              "\n",
              "  Altitude_Category                                   geocoded_address  \\\n",
              "0      Low Altitude     Aeugst am Albis, Bezirk Affoltern, Switzerland   \n",
              "1      Low Altitude               Bucheon-si, Gyeonggi-do, South Korea   \n",
              "2      Low Altitude  South Korea, Incheon, Gajwa 3(sam)-dong, Bangc...   \n",
              "3      Low Altitude                 Yeonhui-dong, Incheon, South Korea   \n",
              "4      Low Altitude               Bucheon-si, Gyeonggi-do, South Korea   \n",
              "\n",
              "  address_match File Name Average PEFR  Standard Deviation PEFR  \n",
              "0         False    SB-001   350.852018                43.013128  \n",
              "1          True    SB-002   501.305410                30.292847  \n",
              "2          True    SB-003   467.173709                 9.081030  \n",
              "3          True    SB-004   320.153509                19.270244  \n",
              "4          True    SB-005          NaN                      NaN  \n",
              "\n",
              "[5 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c4b8cd2-0fac-4e0a-a27c-d17f999d05ed\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ID</th>\n",
              "      <th>BCODE</th>\n",
              "      <th>UID1</th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Smoke</th>\n",
              "      <th>Smoke_amount</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>...</th>\n",
              "      <th>Smoking_intensity</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>altitude</th>\n",
              "      <th>Altitude_Category</th>\n",
              "      <th>geocoded_address</th>\n",
              "      <th>address_match</th>\n",
              "      <th>File Name</th>\n",
              "      <th>Average PEFR</th>\n",
              "      <th>Standard Deviation PEFR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>SB-001</td>\n",
              "      <td>14631875</td>\n",
              "      <td>BC4386476</td>\n",
              "      <td>43</td>\n",
              "      <td>M</td>\n",
              "      <td>NS</td>\n",
              "      <td>0</td>\n",
              "      <td>156</td>\n",
              "      <td>76</td>\n",
              "      <td>...</td>\n",
              "      <td>Non-smoker</td>\n",
              "      <td>47.275410</td>\n",
              "      <td>8.489700</td>\n",
              "      <td>749.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Aeugst am Albis, Bezirk Affoltern, Switzerland</td>\n",
              "      <td>False</td>\n",
              "      <td>SB-001</td>\n",
              "      <td>350.852018</td>\n",
              "      <td>43.013128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>SB-002</td>\n",
              "      <td>14010074</td>\n",
              "      <td>BC3298156</td>\n",
              "      <td>66</td>\n",
              "      <td>M</td>\n",
              "      <td>NS</td>\n",
              "      <td>0</td>\n",
              "      <td>163</td>\n",
              "      <td>58</td>\n",
              "      <td>...</td>\n",
              "      <td>Non-smoker</td>\n",
              "      <td>37.498890</td>\n",
              "      <td>126.783060</td>\n",
              "      <td>15.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Bucheon-si, Gyeonggi-do, South Korea</td>\n",
              "      <td>True</td>\n",
              "      <td>SB-002</td>\n",
              "      <td>501.305410</td>\n",
              "      <td>30.292847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>SB-003</td>\n",
              "      <td>14221420</td>\n",
              "      <td>BC4165314</td>\n",
              "      <td>61</td>\n",
              "      <td>M</td>\n",
              "      <td>ES</td>\n",
              "      <td>20</td>\n",
              "      <td>173</td>\n",
              "      <td>67</td>\n",
              "      <td>...</td>\n",
              "      <td>Light smoker</td>\n",
              "      <td>37.474580</td>\n",
              "      <td>126.680240</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>South Korea, Incheon, Gajwa 3(sam)-dong, Bangc...</td>\n",
              "      <td>True</td>\n",
              "      <td>SB-003</td>\n",
              "      <td>467.173709</td>\n",
              "      <td>9.081030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>SB-004</td>\n",
              "      <td>14010592</td>\n",
              "      <td>BC4201070</td>\n",
              "      <td>49</td>\n",
              "      <td>M</td>\n",
              "      <td>NS</td>\n",
              "      <td>0</td>\n",
              "      <td>142</td>\n",
              "      <td>51</td>\n",
              "      <td>...</td>\n",
              "      <td>Non-smoker</td>\n",
              "      <td>37.548639</td>\n",
              "      <td>126.682664</td>\n",
              "      <td>38.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Yeonhui-dong, Incheon, South Korea</td>\n",
              "      <td>True</td>\n",
              "      <td>SB-004</td>\n",
              "      <td>320.153509</td>\n",
              "      <td>19.270244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>SB-005</td>\n",
              "      <td>14010759</td>\n",
              "      <td>BC4212692</td>\n",
              "      <td>53</td>\n",
              "      <td>M</td>\n",
              "      <td>NS</td>\n",
              "      <td>0</td>\n",
              "      <td>156</td>\n",
              "      <td>70</td>\n",
              "      <td>...</td>\n",
              "      <td>Non-smoker</td>\n",
              "      <td>37.498890</td>\n",
              "      <td>126.783060</td>\n",
              "      <td>15.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Bucheon-si, Gyeonggi-do, South Korea</td>\n",
              "      <td>True</td>\n",
              "      <td>SB-005</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 28 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c4b8cd2-0fac-4e0a-a27c-d17f999d05ed')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6c4b8cd2-0fac-4e0a-a27c-d17f999d05ed button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6c4b8cd2-0fac-4e0a-a27c-d17f999d05ed');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0102aaaa-3ffe-48d2-ac46-ff3ad5446b24\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0102aaaa-3ffe-48d2-ac46-ff3ad5446b24')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0102aaaa-3ffe-48d2-ac46-ff3ad5446b24 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop('File Name', axis=1)"
      ],
      "metadata": {
        "id": "gkzZzK4qAsTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "n3yLFvikA5yh",
        "outputId": "099ed182-bdd3-4c84-b427-542ce624e264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0      ID     BCODE       UID1  Age Sex Smoke  Smoke_amount  \\\n",
              "0           0  SB-001  14631875  BC4386476   43   M    NS             0   \n",
              "1           1  SB-002  14010074  BC3298156   66   M    NS             0   \n",
              "2           2  SB-003  14221420  BC4165314   61   M    ES            20   \n",
              "3           3  SB-004  14010592  BC4201070   49   M    NS             0   \n",
              "4           4  SB-005  14010759  BC4212692   53   M    NS             0   \n",
              "\n",
              "   Height  Weight  ...  Smoking_intensity   latitude   longitude altitude  \\\n",
              "0     156      76  ...         Non-smoker  47.275410    8.489700    749.0   \n",
              "1     163      58  ...         Non-smoker  37.498890  126.783060     15.0   \n",
              "2     173      67  ...       Light smoker  37.474580  126.680240     10.0   \n",
              "3     142      51  ...         Non-smoker  37.548639  126.682664     38.0   \n",
              "4     156      70  ...         Non-smoker  37.498890  126.783060     15.0   \n",
              "\n",
              "  Altitude_Category                                   geocoded_address  \\\n",
              "0      Low Altitude     Aeugst am Albis, Bezirk Affoltern, Switzerland   \n",
              "1      Low Altitude               Bucheon-si, Gyeonggi-do, South Korea   \n",
              "2      Low Altitude  South Korea, Incheon, Gajwa 3(sam)-dong, Bangc...   \n",
              "3      Low Altitude                 Yeonhui-dong, Incheon, South Korea   \n",
              "4      Low Altitude               Bucheon-si, Gyeonggi-do, South Korea   \n",
              "\n",
              "  address_match File Name Average PEFR  Standard Deviation PEFR  \n",
              "0         False    SB-001   350.852018                43.013128  \n",
              "1          True    SB-002   501.305410                30.292847  \n",
              "2          True    SB-003   467.173709                 9.081030  \n",
              "3          True    SB-004   320.153509                19.270244  \n",
              "4          True    SB-005          NaN                      NaN  \n",
              "\n",
              "[5 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52921c41-8464-4017-9fac-fae14b852d46\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ID</th>\n",
              "      <th>BCODE</th>\n",
              "      <th>UID1</th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Smoke</th>\n",
              "      <th>Smoke_amount</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>...</th>\n",
              "      <th>Smoking_intensity</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>altitude</th>\n",
              "      <th>Altitude_Category</th>\n",
              "      <th>geocoded_address</th>\n",
              "      <th>address_match</th>\n",
              "      <th>File Name</th>\n",
              "      <th>Average PEFR</th>\n",
              "      <th>Standard Deviation PEFR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>SB-001</td>\n",
              "      <td>14631875</td>\n",
              "      <td>BC4386476</td>\n",
              "      <td>43</td>\n",
              "      <td>M</td>\n",
              "      <td>NS</td>\n",
              "      <td>0</td>\n",
              "      <td>156</td>\n",
              "      <td>76</td>\n",
              "      <td>...</td>\n",
              "      <td>Non-smoker</td>\n",
              "      <td>47.275410</td>\n",
              "      <td>8.489700</td>\n",
              "      <td>749.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Aeugst am Albis, Bezirk Affoltern, Switzerland</td>\n",
              "      <td>False</td>\n",
              "      <td>SB-001</td>\n",
              "      <td>350.852018</td>\n",
              "      <td>43.013128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>SB-002</td>\n",
              "      <td>14010074</td>\n",
              "      <td>BC3298156</td>\n",
              "      <td>66</td>\n",
              "      <td>M</td>\n",
              "      <td>NS</td>\n",
              "      <td>0</td>\n",
              "      <td>163</td>\n",
              "      <td>58</td>\n",
              "      <td>...</td>\n",
              "      <td>Non-smoker</td>\n",
              "      <td>37.498890</td>\n",
              "      <td>126.783060</td>\n",
              "      <td>15.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Bucheon-si, Gyeonggi-do, South Korea</td>\n",
              "      <td>True</td>\n",
              "      <td>SB-002</td>\n",
              "      <td>501.305410</td>\n",
              "      <td>30.292847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>SB-003</td>\n",
              "      <td>14221420</td>\n",
              "      <td>BC4165314</td>\n",
              "      <td>61</td>\n",
              "      <td>M</td>\n",
              "      <td>ES</td>\n",
              "      <td>20</td>\n",
              "      <td>173</td>\n",
              "      <td>67</td>\n",
              "      <td>...</td>\n",
              "      <td>Light smoker</td>\n",
              "      <td>37.474580</td>\n",
              "      <td>126.680240</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>South Korea, Incheon, Gajwa 3(sam)-dong, Bangc...</td>\n",
              "      <td>True</td>\n",
              "      <td>SB-003</td>\n",
              "      <td>467.173709</td>\n",
              "      <td>9.081030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>SB-004</td>\n",
              "      <td>14010592</td>\n",
              "      <td>BC4201070</td>\n",
              "      <td>49</td>\n",
              "      <td>M</td>\n",
              "      <td>NS</td>\n",
              "      <td>0</td>\n",
              "      <td>142</td>\n",
              "      <td>51</td>\n",
              "      <td>...</td>\n",
              "      <td>Non-smoker</td>\n",
              "      <td>37.548639</td>\n",
              "      <td>126.682664</td>\n",
              "      <td>38.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Yeonhui-dong, Incheon, South Korea</td>\n",
              "      <td>True</td>\n",
              "      <td>SB-004</td>\n",
              "      <td>320.153509</td>\n",
              "      <td>19.270244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>SB-005</td>\n",
              "      <td>14010759</td>\n",
              "      <td>BC4212692</td>\n",
              "      <td>53</td>\n",
              "      <td>M</td>\n",
              "      <td>NS</td>\n",
              "      <td>0</td>\n",
              "      <td>156</td>\n",
              "      <td>70</td>\n",
              "      <td>...</td>\n",
              "      <td>Non-smoker</td>\n",
              "      <td>37.498890</td>\n",
              "      <td>126.783060</td>\n",
              "      <td>15.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Bucheon-si, Gyeonggi-do, South Korea</td>\n",
              "      <td>True</td>\n",
              "      <td>SB-005</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 28 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52921c41-8464-4017-9fac-fae14b852d46')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-52921c41-8464-4017-9fac-fae14b852d46 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-52921c41-8464-4017-9fac-fae14b852d46');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e1204808-8aa2-49c5-9fb5-b2a4d1c63b3c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e1204808-8aa2-49c5-9fb5-b2a4d1c63b3c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e1204808-8aa2-49c5-9fb5-b2a4d1c63b3c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgexzpyHB9WE",
        "outputId": "48a8c8db-15a7-468c-995c-d6ac4d97454d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'ID', 'BCODE', 'UID1', 'Age', 'Sex', 'Smoke',\n",
              "       'Smoke_amount', 'Height', 'Weight', 'BMI', 'BSA', 'occupation',\n",
              "       'occupation_english', 'address', 'address_english', 'Age_group',\n",
              "       'BMI_category', 'Smoking_intensity', 'latitude', 'longitude',\n",
              "       'altitude', 'Altitude_Category', 'geocoded_address', 'address_match',\n",
              "       'File Name', 'Average PEFR', 'Standard Deviation PEFR'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values with the mean of 'average_C_PEFR'\n",
        "data['Average PEFR'].fillna(data['Average PEFR'].mean(), inplace=True)\n",
        "data['Standard Deviation PEFR'].fillna(data['Standard Deviation PEFR'].mean(), inplace=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taxLOmHkA7-r",
        "outputId": "1ac5c9c3-6a84-4abe-cffb-e1de2a0d52fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-69e4ba5886e3>:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Average PEFR'].fillna(data['Average PEFR'].mean(), inplace=True)\n",
            "<ipython-input-32-69e4ba5886e3>:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Standard Deviation PEFR'].fillna(data['Standard Deviation PEFR'].mean(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HJIk9PdWB5-x",
        "outputId": "cf68b7a2-ddc8-47f2-91c7-b2c5e80f9d9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Unnamed: 0      ID     BCODE       UID1  Age Sex Smoke  Smoke_amount  \\\n",
              "0            0  SB-001  14631875  BC4386476   43   M    NS             0   \n",
              "1            1  SB-002  14010074  BC3298156   66   M    NS             0   \n",
              "2            2  SB-003  14221420  BC4165314   61   M    ES            20   \n",
              "3            3  SB-004  14010592  BC4201070   49   M    NS             0   \n",
              "4            4  SB-005  14010759  BC4212692   53   M    NS             0   \n",
              "5            5  SB-006  14004499  BC3766091   64   M    ES            17   \n",
              "6            6  SB-007  14324426  BC4350946   46   M    NS             0   \n",
              "7            7  SB-008  14742620  BC4326814   54   M    ES            10   \n",
              "8            8  SB-009  14411810  BC4429064   63   M    NS             0   \n",
              "9            9  SB-010  14009628  BC3709242   50   M    NS             0   \n",
              "10          10  SB-011  14471611  BC3769955   64   M    NS             0   \n",
              "11          11  SB-012  14258839  BC4315684   65   M    NS             0   \n",
              "12          12  SB-013  14000009  SC4476058   60   M    NS             0   \n",
              "13          13  SB-014  14012817  BC4259685   79   M    ES             2   \n",
              "14          14  SB-015  14005771  BC3832388   80   M    ES            20   \n",
              "\n",
              "    Height  Weight  ...  Smoking_intensity   latitude   longitude altitude  \\\n",
              "0      156      76  ...         Non-smoker  47.275410    8.489700    749.0   \n",
              "1      163      58  ...         Non-smoker  37.498890  126.783060     15.0   \n",
              "2      173      67  ...       Light smoker  37.474580  126.680240     10.0   \n",
              "3      142      51  ...         Non-smoker  37.548639  126.682664     38.0   \n",
              "4      156      70  ...         Non-smoker  37.498890  126.783060     15.0   \n",
              "5      172      80  ...       Light smoker  37.581780  127.090340     33.0   \n",
              "6      155      52  ...         Non-smoker  35.182060  129.082850     20.0   \n",
              "7      173      72  ...       Light smoker  -4.271820  104.099140    100.0   \n",
              "8      158      51  ...         Non-smoker  37.557192  127.171589     22.0   \n",
              "9      156      47  ...         Non-smoker  37.523060  126.744720     13.0   \n",
              "10     154      55  ...         Non-smoker  37.523060  126.744720     13.0   \n",
              "11     160      50  ...         Non-smoker  37.656390  126.835000     20.0   \n",
              "12     151      63  ...         Non-smoker        NaN         NaN      NaN   \n",
              "13     171      70  ...         Non-smoker  37.522980  127.000560     47.0   \n",
              "14     162      63  ...       Light smoker  37.483510  126.619540      8.0   \n",
              "\n",
              "   Altitude_Category                                   geocoded_address  \\\n",
              "0       Low Altitude     Aeugst am Albis, Bezirk Affoltern, Switzerland   \n",
              "1       Low Altitude               Bucheon-si, Gyeonggi-do, South Korea   \n",
              "2       Low Altitude  South Korea, Incheon, Gajwa 3(sam)-dong, Bangc...   \n",
              "3       Low Altitude                 Yeonhui-dong, Incheon, South Korea   \n",
              "4       Low Altitude               Bucheon-si, Gyeonggi-do, South Korea   \n",
              "5       Low Altitude  South Korea, Seoul, Myeonmok 3·8(sam·pal)-dong...   \n",
              "6       Low Altitude                             Yeonje-gu, South Korea   \n",
              "7       Low Altitude             Kabupaten Ogan Komering Ulu, Indonesia   \n",
              "8       Low Altitude  South Korea, Seoul, Sangil 1(il)-dong, Godeok-...   \n",
              "9       Low Altitude                   Gyeyang-gu, Incheon, South Korea   \n",
              "10      Low Altitude                   Gyeyang-gu, Incheon, South Korea   \n",
              "11      Low Altitude                Goyang-si, Gyeonggi-do, South Korea   \n",
              "12      Low Altitude                                                NaN   \n",
              "13      Low Altitude              Bogwang-dong, Yongsan-gu, South Korea   \n",
              "14      Low Altitude                 Manseok-dong, Dong-gu, South Korea   \n",
              "\n",
              "   address_match File Name Average PEFR  Standard Deviation PEFR  \n",
              "0          False    SB-001   350.852018                43.013128  \n",
              "1           True    SB-002   501.305410                30.292847  \n",
              "2           True    SB-003   467.173709                 9.081030  \n",
              "3           True    SB-004   320.153509                19.270244  \n",
              "4           True    SB-005   380.049686                33.215461  \n",
              "5           True    SB-006   443.670181                21.288338  \n",
              "6           True    SB-007   308.167742                36.053506  \n",
              "7          False    SB-008   585.694431                22.583346  \n",
              "8           True    SB-009   320.954918                15.390041  \n",
              "9           True    SB-010   118.608209                35.705824  \n",
              "10          True    SB-011   204.446036                27.193520  \n",
              "11          True    SB-012   326.984874                20.558976  \n",
              "12         False    SB-013   128.869509                21.780684  \n",
              "13          True    SB-014   417.975474                58.700137  \n",
              "14          True    SB-015   352.204368                15.552845  \n",
              "\n",
              "[15 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0cdcb3bf-a369-44ff-b8db-3876ec81d135\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ID</th>\n",
              "      <th>BCODE</th>\n",
              "      <th>UID1</th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Smoke</th>\n",
              "      <th>Smoke_amount</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>...</th>\n",
              "      <th>Smoking_intensity</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>altitude</th>\n",
              "      <th>Altitude_Category</th>\n",
              "      <th>geocoded_address</th>\n",
              "      <th>address_match</th>\n",
              "      <th>File Name</th>\n",
              "      <th>Average PEFR</th>\n",
              "      <th>Standard Deviation PEFR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>SB-001</td>\n",
              "      <td>14631875</td>\n",
              "      <td>BC4386476</td>\n",
              "      <td>43</td>\n",
              "      <td>M</td>\n",
              "      <td>NS</td>\n",
              "      <td>0</td>\n",
              "      <td>156</td>\n",
              "      <td>76</td>\n",
              "      <td>...</td>\n",
              "      <td>Non-smoker</td>\n",
              "      <td>47.275410</td>\n",
              "      <td>8.489700</td>\n",
              "      <td>749.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Aeugst am Albis, Bezirk Affoltern, Switzerland</td>\n",
              "      <td>False</td>\n",
              "      <td>SB-001</td>\n",
              "      <td>350.852018</td>\n",
              "      <td>43.013128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>SB-002</td>\n",
              "      <td>14010074</td>\n",
              "      <td>BC3298156</td>\n",
              "      <td>66</td>\n",
              "      <td>M</td>\n",
              "      <td>NS</td>\n",
              "      <td>0</td>\n",
              "      <td>163</td>\n",
              "      <td>58</td>\n",
              "      <td>...</td>\n",
              "      <td>Non-smoker</td>\n",
              "      <td>37.498890</td>\n",
              "      <td>126.783060</td>\n",
              "      <td>15.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Bucheon-si, Gyeonggi-do, South Korea</td>\n",
              "      <td>True</td>\n",
              "      <td>SB-002</td>\n",
              "      <td>501.305410</td>\n",
              "      <td>30.292847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>SB-003</td>\n",
              "      <td>14221420</td>\n",
              "      <td>BC4165314</td>\n",
              "      <td>61</td>\n",
              "      <td>M</td>\n",
              "      <td>ES</td>\n",
              "      <td>20</td>\n",
              "      <td>173</td>\n",
              "      <td>67</td>\n",
              "      <td>...</td>\n",
              "      <td>Light smoker</td>\n",
              "      <td>37.474580</td>\n",
              "      <td>126.680240</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>South Korea, Incheon, Gajwa 3(sam)-dong, Bangc...</td>\n",
              "      <td>True</td>\n",
              "      <td>SB-003</td>\n",
              "      <td>467.173709</td>\n",
              "      <td>9.081030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>SB-004</td>\n",
              "      <td>14010592</td>\n",
              "      <td>BC4201070</td>\n",
              "      <td>49</td>\n",
              "      <td>M</td>\n",
              "      <td>NS</td>\n",
              "      <td>0</td>\n",
              "      <td>142</td>\n",
              "      <td>51</td>\n",
              "      <td>...</td>\n",
              "      <td>Non-smoker</td>\n",
              "      <td>37.548639</td>\n",
              "      <td>126.682664</td>\n",
              "      <td>38.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Yeonhui-dong, Incheon, South Korea</td>\n",
              "      <td>True</td>\n",
              "      <td>SB-004</td>\n",
              "      <td>320.153509</td>\n",
              "      <td>19.270244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>SB-005</td>\n",
              "      <td>14010759</td>\n",
              "      <td>BC4212692</td>\n",
              "      <td>53</td>\n",
              "      <td>M</td>\n",
              "      <td>NS</td>\n",
              "      <td>0</td>\n",
              "      <td>156</td>\n",
              "      <td>70</td>\n",
              "      <td>...</td>\n",
              "      <td>Non-smoker</td>\n",
              "      <td>37.498890</td>\n",
              "      <td>126.783060</td>\n",
              "      <td>15.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Bucheon-si, Gyeonggi-do, South Korea</td>\n",
              "      <td>True</td>\n",
              "      <td>SB-005</td>\n",
              "      <td>380.049686</td>\n",
              "      <td>33.215461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>SB-006</td>\n",
              "      <td>14004499</td>\n",
              "      <td>BC3766091</td>\n",
              "      <td>64</td>\n",
              "      <td>M</td>\n",
              "      <td>ES</td>\n",
              "      <td>17</td>\n",
              "      <td>172</td>\n",
              "      <td>80</td>\n",
              "      <td>...</td>\n",
              "      <td>Light smoker</td>\n",
              "      <td>37.581780</td>\n",
              "      <td>127.090340</td>\n",
              "      <td>33.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>South Korea, Seoul, Myeonmok 3·8(sam·pal)-dong...</td>\n",
              "      <td>True</td>\n",
              "      <td>SB-006</td>\n",
              "      <td>443.670181</td>\n",
              "      <td>21.288338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>SB-007</td>\n",
              "      <td>14324426</td>\n",
              "      <td>BC4350946</td>\n",
              "      <td>46</td>\n",
              "      <td>M</td>\n",
              "      <td>NS</td>\n",
              "      <td>0</td>\n",
              "      <td>155</td>\n",
              "      <td>52</td>\n",
              "      <td>...</td>\n",
              "      <td>Non-smoker</td>\n",
              "      <td>35.182060</td>\n",
              "      <td>129.082850</td>\n",
              "      <td>20.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Yeonje-gu, South Korea</td>\n",
              "      <td>True</td>\n",
              "      <td>SB-007</td>\n",
              "      <td>308.167742</td>\n",
              "      <td>36.053506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>SB-008</td>\n",
              "      <td>14742620</td>\n",
              "      <td>BC4326814</td>\n",
              "      <td>54</td>\n",
              "      <td>M</td>\n",
              "      <td>ES</td>\n",
              "      <td>10</td>\n",
              "      <td>173</td>\n",
              "      <td>72</td>\n",
              "      <td>...</td>\n",
              "      <td>Light smoker</td>\n",
              "      <td>-4.271820</td>\n",
              "      <td>104.099140</td>\n",
              "      <td>100.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Kabupaten Ogan Komering Ulu, Indonesia</td>\n",
              "      <td>False</td>\n",
              "      <td>SB-008</td>\n",
              "      <td>585.694431</td>\n",
              "      <td>22.583346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>SB-009</td>\n",
              "      <td>14411810</td>\n",
              "      <td>BC4429064</td>\n",
              "      <td>63</td>\n",
              "      <td>M</td>\n",
              "      <td>NS</td>\n",
              "      <td>0</td>\n",
              "      <td>158</td>\n",
              "      <td>51</td>\n",
              "      <td>...</td>\n",
              "      <td>Non-smoker</td>\n",
              "      <td>37.557192</td>\n",
              "      <td>127.171589</td>\n",
              "      <td>22.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>South Korea, Seoul, Sangil 1(il)-dong, Godeok-...</td>\n",
              "      <td>True</td>\n",
              "      <td>SB-009</td>\n",
              "      <td>320.954918</td>\n",
              "      <td>15.390041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>SB-010</td>\n",
              "      <td>14009628</td>\n",
              "      <td>BC3709242</td>\n",
              "      <td>50</td>\n",
              "      <td>M</td>\n",
              "      <td>NS</td>\n",
              "      <td>0</td>\n",
              "      <td>156</td>\n",
              "      <td>47</td>\n",
              "      <td>...</td>\n",
              "      <td>Non-smoker</td>\n",
              "      <td>37.523060</td>\n",
              "      <td>126.744720</td>\n",
              "      <td>13.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Gyeyang-gu, Incheon, South Korea</td>\n",
              "      <td>True</td>\n",
              "      <td>SB-010</td>\n",
              "      <td>118.608209</td>\n",
              "      <td>35.705824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>SB-011</td>\n",
              "      <td>14471611</td>\n",
              "      <td>BC3769955</td>\n",
              "      <td>64</td>\n",
              "      <td>M</td>\n",
              "      <td>NS</td>\n",
              "      <td>0</td>\n",
              "      <td>154</td>\n",
              "      <td>55</td>\n",
              "      <td>...</td>\n",
              "      <td>Non-smoker</td>\n",
              "      <td>37.523060</td>\n",
              "      <td>126.744720</td>\n",
              "      <td>13.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Gyeyang-gu, Incheon, South Korea</td>\n",
              "      <td>True</td>\n",
              "      <td>SB-011</td>\n",
              "      <td>204.446036</td>\n",
              "      <td>27.193520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>SB-012</td>\n",
              "      <td>14258839</td>\n",
              "      <td>BC4315684</td>\n",
              "      <td>65</td>\n",
              "      <td>M</td>\n",
              "      <td>NS</td>\n",
              "      <td>0</td>\n",
              "      <td>160</td>\n",
              "      <td>50</td>\n",
              "      <td>...</td>\n",
              "      <td>Non-smoker</td>\n",
              "      <td>37.656390</td>\n",
              "      <td>126.835000</td>\n",
              "      <td>20.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Goyang-si, Gyeonggi-do, South Korea</td>\n",
              "      <td>True</td>\n",
              "      <td>SB-012</td>\n",
              "      <td>326.984874</td>\n",
              "      <td>20.558976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>SB-013</td>\n",
              "      <td>14000009</td>\n",
              "      <td>SC4476058</td>\n",
              "      <td>60</td>\n",
              "      <td>M</td>\n",
              "      <td>NS</td>\n",
              "      <td>0</td>\n",
              "      <td>151</td>\n",
              "      <td>63</td>\n",
              "      <td>...</td>\n",
              "      <td>Non-smoker</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>SB-013</td>\n",
              "      <td>128.869509</td>\n",
              "      <td>21.780684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>SB-014</td>\n",
              "      <td>14012817</td>\n",
              "      <td>BC4259685</td>\n",
              "      <td>79</td>\n",
              "      <td>M</td>\n",
              "      <td>ES</td>\n",
              "      <td>2</td>\n",
              "      <td>171</td>\n",
              "      <td>70</td>\n",
              "      <td>...</td>\n",
              "      <td>Non-smoker</td>\n",
              "      <td>37.522980</td>\n",
              "      <td>127.000560</td>\n",
              "      <td>47.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Bogwang-dong, Yongsan-gu, South Korea</td>\n",
              "      <td>True</td>\n",
              "      <td>SB-014</td>\n",
              "      <td>417.975474</td>\n",
              "      <td>58.700137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>SB-015</td>\n",
              "      <td>14005771</td>\n",
              "      <td>BC3832388</td>\n",
              "      <td>80</td>\n",
              "      <td>M</td>\n",
              "      <td>ES</td>\n",
              "      <td>20</td>\n",
              "      <td>162</td>\n",
              "      <td>63</td>\n",
              "      <td>...</td>\n",
              "      <td>Light smoker</td>\n",
              "      <td>37.483510</td>\n",
              "      <td>126.619540</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Manseok-dong, Dong-gu, South Korea</td>\n",
              "      <td>True</td>\n",
              "      <td>SB-015</td>\n",
              "      <td>352.204368</td>\n",
              "      <td>15.552845</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15 rows × 28 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0cdcb3bf-a369-44ff-b8db-3876ec81d135')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0cdcb3bf-a369-44ff-b8db-3876ec81d135 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0cdcb3bf-a369-44ff-b8db-3876ec81d135');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5120ca94-3ac7-43b3-975a-a3a422d13f17\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5120ca94-3ac7-43b3-975a-a3a422d13f17')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5120ca94-3ac7-43b3-975a-a3a422d13f17 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0zjW5M10CyRt",
        "outputId": "d83d2eb6-f411-444b-9321-735510df6329"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0      ID     BCODE       UID1  Age Sex Smoke  Smoke_amount  \\\n",
              "99           99  SB-122  14002615  BC3564490   72   M    NS             0   \n",
              "100         100  SB-123  14002570  BC3460634   64   F    NS             0   \n",
              "101         101  SB-124  14002278  BC3541816   55   F    NS             0   \n",
              "102         102  SB-126  14001946  BC3515750   66   M    NS             0   \n",
              "103         103  SB-127  14001878  BC3418106   57   M    NS             0   \n",
              "104         104  SB-128  14001766  BC3494890   72   F    ES            40   \n",
              "105         105  SB-130  14001501  BC3457672   69   F    ES            10   \n",
              "106         106  SB-131  14001448  BC3442060   51   M    SM            20   \n",
              "107         107  SB-132  14001232  BC3414119   61   F    NS             0   \n",
              "108         108  SB-133  14001215  BC3308442   83   M    NS             0   \n",
              "109         109  SB-135  14000819  BC3296833   79   M    NS             0   \n",
              "110         110  SB-137  14000774  BC3300701   76   F    NS             0   \n",
              "111         111  SB-139  14000670  BC3334855   50   F    ES            20   \n",
              "112         112  SB-140  14000334  BC3309595   69   F    ES            15   \n",
              "113         113  SB-141  14000223  BC3294749   71   F    NS             0   \n",
              "\n",
              "     Height  Weight  ...  Smoking_intensity   latitude   longitude altitude  \\\n",
              "99      158      47  ...         Non-smoker  37.495180  126.720070     17.0   \n",
              "100     154      71  ...         Non-smoker  37.490698  126.723817     20.0   \n",
              "101     150      48  ...         Non-smoker  37.498890  126.783060     15.0   \n",
              "102     143      53  ...         Non-smoker  37.498890  126.783060     15.0   \n",
              "103     161      62  ...         Non-smoker  35.238200  128.692500     64.0   \n",
              "104     162      60  ...       Heavy smoker  37.494470  126.850200     14.0   \n",
              "105     165      75  ...       Light smoker  37.450230  126.799080     32.0   \n",
              "106     166      70  ...       Light smoker  25.406758   55.444939      7.0   \n",
              "107     154      40  ...         Non-smoker  37.495180  126.720070     17.0   \n",
              "108     157      60  ...         Non-smoker        NaN         NaN      NaN   \n",
              "109     163      67  ...         Non-smoker  37.512130  126.785189     21.0   \n",
              "110     160      66  ...         Non-smoker  37.498890  126.783060     15.0   \n",
              "111     162      64  ...       Light smoker  34.621465  135.533049      8.0   \n",
              "112     170      72  ...       Light smoker  37.498890  126.783060     15.0   \n",
              "113     162      73  ...         Non-smoker  37.498890  126.783060     15.0   \n",
              "\n",
              "    Altitude_Category                                   geocoded_address  \\\n",
              "99       Low Altitude                           Bupyeong-gu, South Korea   \n",
              "100      Low Altitude                Bupyeong-dong, Incheon, South Korea   \n",
              "101      Low Altitude               Bucheon-si, Gyeonggi-do, South Korea   \n",
              "102      Low Altitude               Bucheon-si, Gyeonggi-do, South Korea   \n",
              "103      Low Altitude                      South Gyeongsang, South Korea   \n",
              "104      Low Altitude                               Guro-gu, South Korea   \n",
              "105      Low Altitude                Daeya-dong, Siheung-si, South Korea   \n",
              "106      Low Altitude  Hana'a, 6 Street, Al Bustan, Ajman, Ajman Emir...   \n",
              "107      Low Altitude                           Bupyeong-gu, South Korea   \n",
              "108      Low Altitude                                                NaN   \n",
              "109      Low Altitude  South Korea, Gyeonggi, Bucheon-si, Wonmi-gu, 1...   \n",
              "110      Low Altitude               Bucheon-si, Gyeonggi-do, South Korea   \n",
              "111      Low Altitude  Hanshin Expressway Route 14 Matsubara Line, Hi...   \n",
              "112      Low Altitude               Bucheon-si, Gyeonggi-do, South Korea   \n",
              "113      Low Altitude               Bucheon-si, Gyeonggi-do, South Korea   \n",
              "\n",
              "    address_match File Name Average PEFR  Standard Deviation PEFR  \n",
              "99           True    SB-122   258.814924                18.181080  \n",
              "100          True       NaN   380.049686                33.215461  \n",
              "101          True       NaN   380.049686                33.215461  \n",
              "102          True       NaN   380.049686                33.215461  \n",
              "103          True       NaN   380.049686                33.215461  \n",
              "104          True       NaN   380.049686                33.215461  \n",
              "105          True       NaN   380.049686                33.215461  \n",
              "106         False       NaN   380.049686                33.215461  \n",
              "107          True       NaN   380.049686                33.215461  \n",
              "108         False       NaN   380.049686                33.215461  \n",
              "109          True       NaN   380.049686                33.215461  \n",
              "110          True       NaN   380.049686                33.215461  \n",
              "111         False       NaN   380.049686                33.215461  \n",
              "112          True       NaN   380.049686                33.215461  \n",
              "113          True       NaN   380.049686                33.215461  \n",
              "\n",
              "[15 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dae312fc-8b5b-4576-9b53-0183f70bcbbc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ID</th>\n",
              "      <th>BCODE</th>\n",
              "      <th>UID1</th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Smoke</th>\n",
              "      <th>Smoke_amount</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>...</th>\n",
              "      <th>Smoking_intensity</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>altitude</th>\n",
              "      <th>Altitude_Category</th>\n",
              "      <th>geocoded_address</th>\n",
              "      <th>address_match</th>\n",
              "      <th>File Name</th>\n",
              "      <th>Average PEFR</th>\n",
              "      <th>Standard Deviation PEFR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>SB-122</td>\n",
              "      <td>14002615</td>\n",
              "      <td>BC3564490</td>\n",
              "      <td>72</td>\n",
              "      <td>M</td>\n",
              "      <td>NS</td>\n",
              "      <td>0</td>\n",
              "      <td>158</td>\n",
              "      <td>47</td>\n",
              "      <td>...</td>\n",
              "      <td>Non-smoker</td>\n",
              "      <td>37.495180</td>\n",
              "      <td>126.720070</td>\n",
              "      <td>17.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Bupyeong-gu, South Korea</td>\n",
              "      <td>True</td>\n",
              "      <td>SB-122</td>\n",
              "      <td>258.814924</td>\n",
              "      <td>18.181080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>100</td>\n",
              "      <td>SB-123</td>\n",
              "      <td>14002570</td>\n",
              "      <td>BC3460634</td>\n",
              "      <td>64</td>\n",
              "      <td>F</td>\n",
              "      <td>NS</td>\n",
              "      <td>0</td>\n",
              "      <td>154</td>\n",
              "      <td>71</td>\n",
              "      <td>...</td>\n",
              "      <td>Non-smoker</td>\n",
              "      <td>37.490698</td>\n",
              "      <td>126.723817</td>\n",
              "      <td>20.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Bupyeong-dong, Incheon, South Korea</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>380.049686</td>\n",
              "      <td>33.215461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>101</td>\n",
              "      <td>SB-124</td>\n",
              "      <td>14002278</td>\n",
              "      <td>BC3541816</td>\n",
              "      <td>55</td>\n",
              "      <td>F</td>\n",
              "      <td>NS</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>48</td>\n",
              "      <td>...</td>\n",
              "      <td>Non-smoker</td>\n",
              "      <td>37.498890</td>\n",
              "      <td>126.783060</td>\n",
              "      <td>15.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Bucheon-si, Gyeonggi-do, South Korea</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>380.049686</td>\n",
              "      <td>33.215461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>102</td>\n",
              "      <td>SB-126</td>\n",
              "      <td>14001946</td>\n",
              "      <td>BC3515750</td>\n",
              "      <td>66</td>\n",
              "      <td>M</td>\n",
              "      <td>NS</td>\n",
              "      <td>0</td>\n",
              "      <td>143</td>\n",
              "      <td>53</td>\n",
              "      <td>...</td>\n",
              "      <td>Non-smoker</td>\n",
              "      <td>37.498890</td>\n",
              "      <td>126.783060</td>\n",
              "      <td>15.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Bucheon-si, Gyeonggi-do, South Korea</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>380.049686</td>\n",
              "      <td>33.215461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>103</td>\n",
              "      <td>SB-127</td>\n",
              "      <td>14001878</td>\n",
              "      <td>BC3418106</td>\n",
              "      <td>57</td>\n",
              "      <td>M</td>\n",
              "      <td>NS</td>\n",
              "      <td>0</td>\n",
              "      <td>161</td>\n",
              "      <td>62</td>\n",
              "      <td>...</td>\n",
              "      <td>Non-smoker</td>\n",
              "      <td>35.238200</td>\n",
              "      <td>128.692500</td>\n",
              "      <td>64.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>South Gyeongsang, South Korea</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>380.049686</td>\n",
              "      <td>33.215461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>104</td>\n",
              "      <td>SB-128</td>\n",
              "      <td>14001766</td>\n",
              "      <td>BC3494890</td>\n",
              "      <td>72</td>\n",
              "      <td>F</td>\n",
              "      <td>ES</td>\n",
              "      <td>40</td>\n",
              "      <td>162</td>\n",
              "      <td>60</td>\n",
              "      <td>...</td>\n",
              "      <td>Heavy smoker</td>\n",
              "      <td>37.494470</td>\n",
              "      <td>126.850200</td>\n",
              "      <td>14.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Guro-gu, South Korea</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>380.049686</td>\n",
              "      <td>33.215461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>105</td>\n",
              "      <td>SB-130</td>\n",
              "      <td>14001501</td>\n",
              "      <td>BC3457672</td>\n",
              "      <td>69</td>\n",
              "      <td>F</td>\n",
              "      <td>ES</td>\n",
              "      <td>10</td>\n",
              "      <td>165</td>\n",
              "      <td>75</td>\n",
              "      <td>...</td>\n",
              "      <td>Light smoker</td>\n",
              "      <td>37.450230</td>\n",
              "      <td>126.799080</td>\n",
              "      <td>32.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Daeya-dong, Siheung-si, South Korea</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>380.049686</td>\n",
              "      <td>33.215461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>106</td>\n",
              "      <td>SB-131</td>\n",
              "      <td>14001448</td>\n",
              "      <td>BC3442060</td>\n",
              "      <td>51</td>\n",
              "      <td>M</td>\n",
              "      <td>SM</td>\n",
              "      <td>20</td>\n",
              "      <td>166</td>\n",
              "      <td>70</td>\n",
              "      <td>...</td>\n",
              "      <td>Light smoker</td>\n",
              "      <td>25.406758</td>\n",
              "      <td>55.444939</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Hana'a, 6 Street, Al Bustan, Ajman, Ajman Emir...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>380.049686</td>\n",
              "      <td>33.215461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>107</td>\n",
              "      <td>SB-132</td>\n",
              "      <td>14001232</td>\n",
              "      <td>BC3414119</td>\n",
              "      <td>61</td>\n",
              "      <td>F</td>\n",
              "      <td>NS</td>\n",
              "      <td>0</td>\n",
              "      <td>154</td>\n",
              "      <td>40</td>\n",
              "      <td>...</td>\n",
              "      <td>Non-smoker</td>\n",
              "      <td>37.495180</td>\n",
              "      <td>126.720070</td>\n",
              "      <td>17.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Bupyeong-gu, South Korea</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>380.049686</td>\n",
              "      <td>33.215461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>108</td>\n",
              "      <td>SB-133</td>\n",
              "      <td>14001215</td>\n",
              "      <td>BC3308442</td>\n",
              "      <td>83</td>\n",
              "      <td>M</td>\n",
              "      <td>NS</td>\n",
              "      <td>0</td>\n",
              "      <td>157</td>\n",
              "      <td>60</td>\n",
              "      <td>...</td>\n",
              "      <td>Non-smoker</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>380.049686</td>\n",
              "      <td>33.215461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>109</td>\n",
              "      <td>SB-135</td>\n",
              "      <td>14000819</td>\n",
              "      <td>BC3296833</td>\n",
              "      <td>79</td>\n",
              "      <td>M</td>\n",
              "      <td>NS</td>\n",
              "      <td>0</td>\n",
              "      <td>163</td>\n",
              "      <td>67</td>\n",
              "      <td>...</td>\n",
              "      <td>Non-smoker</td>\n",
              "      <td>37.512130</td>\n",
              "      <td>126.785189</td>\n",
              "      <td>21.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>South Korea, Gyeonggi, Bucheon-si, Wonmi-gu, 1...</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>380.049686</td>\n",
              "      <td>33.215461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>110</td>\n",
              "      <td>SB-137</td>\n",
              "      <td>14000774</td>\n",
              "      <td>BC3300701</td>\n",
              "      <td>76</td>\n",
              "      <td>F</td>\n",
              "      <td>NS</td>\n",
              "      <td>0</td>\n",
              "      <td>160</td>\n",
              "      <td>66</td>\n",
              "      <td>...</td>\n",
              "      <td>Non-smoker</td>\n",
              "      <td>37.498890</td>\n",
              "      <td>126.783060</td>\n",
              "      <td>15.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Bucheon-si, Gyeonggi-do, South Korea</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>380.049686</td>\n",
              "      <td>33.215461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>111</td>\n",
              "      <td>SB-139</td>\n",
              "      <td>14000670</td>\n",
              "      <td>BC3334855</td>\n",
              "      <td>50</td>\n",
              "      <td>F</td>\n",
              "      <td>ES</td>\n",
              "      <td>20</td>\n",
              "      <td>162</td>\n",
              "      <td>64</td>\n",
              "      <td>...</td>\n",
              "      <td>Light smoker</td>\n",
              "      <td>34.621465</td>\n",
              "      <td>135.533049</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Hanshin Expressway Route 14 Matsubara Line, Hi...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>380.049686</td>\n",
              "      <td>33.215461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>112</td>\n",
              "      <td>SB-140</td>\n",
              "      <td>14000334</td>\n",
              "      <td>BC3309595</td>\n",
              "      <td>69</td>\n",
              "      <td>F</td>\n",
              "      <td>ES</td>\n",
              "      <td>15</td>\n",
              "      <td>170</td>\n",
              "      <td>72</td>\n",
              "      <td>...</td>\n",
              "      <td>Light smoker</td>\n",
              "      <td>37.498890</td>\n",
              "      <td>126.783060</td>\n",
              "      <td>15.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Bucheon-si, Gyeonggi-do, South Korea</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>380.049686</td>\n",
              "      <td>33.215461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>113</td>\n",
              "      <td>SB-141</td>\n",
              "      <td>14000223</td>\n",
              "      <td>BC3294749</td>\n",
              "      <td>71</td>\n",
              "      <td>F</td>\n",
              "      <td>NS</td>\n",
              "      <td>0</td>\n",
              "      <td>162</td>\n",
              "      <td>73</td>\n",
              "      <td>...</td>\n",
              "      <td>Non-smoker</td>\n",
              "      <td>37.498890</td>\n",
              "      <td>126.783060</td>\n",
              "      <td>15.0</td>\n",
              "      <td>Low Altitude</td>\n",
              "      <td>Bucheon-si, Gyeonggi-do, South Korea</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>380.049686</td>\n",
              "      <td>33.215461</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15 rows × 28 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dae312fc-8b5b-4576-9b53-0183f70bcbbc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dae312fc-8b5b-4576-9b53-0183f70bcbbc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dae312fc-8b5b-4576-9b53-0183f70bcbbc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1facc314-7357-4f40-a884-8a626c3d8b9f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1facc314-7357-4f40-a884-8a626c3d8b9f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1facc314-7357-4f40-a884-8a626c3d8b9f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['Average PEFR'] = data['Average PEFR'].round(2) # Round to 2 decimal places\n",
        "data['Standard Deviation PEFR'] = data['Standard Deviation PEFR'].round(2) # Round to 2 decimal places\n"
      ],
      "metadata": {
        "id": "-W--ATjjlqr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop('File Name', axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "z-h3_RgsZDkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Save the modified dataset to the specified location\n",
        "data.to_csv('/content/drive/My Drive/Patient data individual/2024-Data/CSV_Files/Preprocessed_dataset/matched_data1.csv', index=False)\n",
        "\n",
        "# Download the file\n",
        "files.download('/content/drive/My Drive/Patient data individual/2024-Data/CSV_Files/Preprocessed_dataset/matched_data1.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "rFtrluHYlJXK",
        "outputId": "37efd47a-0a98-4a7d-aed3-a9f337f309bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e3dbbced-334d-4690-9e64-beb9bc432533\", \"matched_data1.csv\", 37542)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S0sfEnxtli2A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}